#!/usr/bin/env python3
"""
Script to identify and mark reappointments based on repeated occurrences
of the same person in the same position at the same organization.
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys

def standardize_name(name):
    """
    Standardize names for better matching.
    Handles None values and basic standardization.
    """
    if pd.isna(name):
        return None
    
    # Convert to string and strip whitespace
    name = str(name).strip()
    
    # Convert to uppercase for comparison
    name = name.upper()
    
    # Remove extra spaces
    name = ' '.join(name.split())
    
    return name

def main():
    # Define paths
    base_path = Path.cwd()
    data_dir = base_path / "scripts" / "claudeopus4" / "version1" / "execution3" / "analysis_data"
    input_file = data_dir / "step2_key_columns_data.csv"
    output_file = data_dir / "step3_repeats_marked.csv"
    
    # Check if input file exists
    if not input_file.exists():
        print(f"Error: Input file not found at {input_file}")
        sys.exit(1)
    
    print(f"Loading filtered dataset from: {input_file}")
    
    try:
        # Load the dataset
        df = pd.read_csv(input_file, encoding='utf-8')
        print(f"Successfully loaded dataset with shape: {df.shape}")
        
    except Exception as e:
        print(f"Error loading file: {str(e)}")
        sys.exit(1)
    
    # Check required columns exist
    required_columns = ['name', 'position', 'org', 'year']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"Error: Missing required columns: {missing_columns}")
        sys.exit(1)
    
    # Create a copy to work with
    df_work = df.copy()
    
    # Ensure 'reappointed' column exists
    if 'reappointed' not in df_work.columns:
        print("Warning: 'reappointed' column not found. Creating new column.")
        df_work['reappointed'] = False
    
    # Convert reappointed to boolean if it isn't already
    print("\nConverting 'reappointed' column to boolean...")
    df_work['reappointed'] = df_work['reappointed'].fillna(False)
    df_work['reappointed'] = df_work['reappointed'].astype(bool)
    
    # Count existing reappointments
    existing_reappointments = df_work['reappointed'].sum()
    print(f"Existing reappointments marked: {existing_reappointments:,}")
    
    # Standardize names for matching
    print("\nStandardizing names for better matching...")
    df_work['name_standardized'] = df_work['name'].apply(standardize_name)
    
    # Handle missing values in grouping columns
    print("\nHandling missing values in key columns...")
    for col in ['name_standardized', 'position', 'org']:
        missing_count = df_work[col].isna().sum()
        if missing_count > 0:
            print(f"  - {col}: {missing_count:,} missing values")
    
    # Create a mask for valid rows (no missing values in key columns)
    valid_mask = df_work[['name_standardized', 'position', 'org']].notna().all(axis=1)
    print(f"\nRows with complete information: {valid_mask.sum():,} out of {len(df_work):,}")
    
    # Sort by year to ensure chronological order
    print("\nSorting data chronologically...")
    df_work = df_work.sort_values('year', kind='stable').reset_index(drop=True)
    
    # Group by name, position, and org
    print("\nIdentifying repeated appointments...")
    group_columns = ['name_standardized', 'position', 'org']
    
    # Initialize counter for newly identified reappointments
    newly_marked = 0
    
    # Process each group
    for group_key, group_indices in df_work[valid_mask].groupby(group_columns).groups.items():
        # Convert to list for safe indexing
        indices_list = group_indices.tolist()
        
        # Skip if only one occurrence
        if len(indices_list) <= 1:
            continue
        
        # Get the group data sorted by year
        group_data = df_work.loc[indices_list].sort_values('year', kind='stable')
        group_indices_sorted = group_data.index.tolist()
        
        # Mark all except the first as reappointments
        for idx in group_indices_sorted[1:]:
            # Only count as newly marked if it wasn't already marked
            if not df_work.loc[idx, 'reappointed']:
                newly_marked += 1
            df_work.loc[idx, 'reappointed'] = True
    
    # Drop the standardized name column before saving
    df_work = df_work.drop(columns=['name_standardized'])
    
    # Save the updated dataset
    df_work.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nUpdated dataset saved to: {output_file}")
    
    # Print statistics
    print("\n" + "="*50)
    print("REAPPOINTMENT IDENTIFICATION STATISTICS")
    print("="*50)
    
    total_reappointments = df_work['reappointed'].sum()
    print(f"Total appointments in dataset: {len(df_work):,}")
    print(f"Previously marked reappointments: {existing_reappointments:,}")
    print(f"Newly identified reappointments: {newly_marked:,}")
    print(f"Total reappointments after update: {total_reappointments:,}")
    print(f"Percentage of reappointments: {(total_reappointments / len(df_work)) * 100:.1f}%")
    
    # Analyze by year
    print("\nReappointments by year:")
    year_stats = df_work.groupby('year')['reappointed'].agg(['sum', 'count', 'mean'])
    year_stats.columns = ['reappointments', 'total', 'percentage']
    year_stats['percentage'] = year_stats['percentage'] * 100
    
    for year, row in year_stats.iterrows():
        print(f"  - {year}: {int(row['reappointments']):,} out of {int(row['total']):,} ({row['percentage']:.1f}%)")
    
    # Find people with most reappointments
    print("\nTop 10 people with most appointments to same position/org:")
    repeat_counts = df_work[valid_mask].groupby(['name', 'position', 'org']).size()
    repeat_counts = repeat_counts[repeat_counts > 1].sort_values(ascending=False)
    
    for i, ((name, position, org), count) in enumerate(repeat_counts.head(10).items()):
        print(f"  {i+1}. {name} - {position} at {org}: {count} appointments")
    
    # Analyze by organization
    print("\nOrganizations with highest reappointment rates (min 10 appointments):")
    org_stats = df_work.groupby('org').agg({
        'reappointed': ['sum', 'count', 'mean']
    })
    org_stats.columns = ['reappointments', 'total', 'rate']
    org_stats = org_stats[org_stats['total'] >= 10]
    org_stats = org_stats.sort_values('rate', ascending=False).head(10)
    
    for org, row in org_stats.iterrows():
        print(f"  - {org}: {row['rate']*100:.1f}% ({int(row['reappointments'])} of {int(row['total'])})")
    
    print("\n" + "="*50)
    print("Script completed successfully!")

if __name__ == "__main__":
    main()