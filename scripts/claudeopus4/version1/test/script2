#!/usr/bin/env python3
"""
step to extract key columns from the combined appointments dataset
Handles variations in column naming and creates a filtered dataset
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys

def find_matching_column(df, possible_names):
    """
    Find a column in the dataframe that matches one of the possible names
    Case-insensitive matching
    
    Args:
        df: pandas DataFrame
        possible_names: list of possible column names
    
    Returns:
        str: matching column name from the dataframe, or None if not found
    """
    # Get lowercase versions of all column names in the dataframe
    df_columns_lower = {col.lower(): col for col in df.columns}
    
    # Check each possible name
    for name in possible_names:
        if name.lower() in df_columns_lower:
            return df_columns_lower[name.lower()]
    
    return None

def extract_key_columns():
    """
    Load combined dataset and extract key columns with robust column name handling
    """
    # Define paths
    data_dir = Path("steps/claudeopus4/version1/analysis_data")
    input_file = data_dir / "step1_combined_appointments.csv"
    output_file = data_dir / "step2_key_columns_data.csv"
    
    # Check if input file exists
    if not input_file.exists():
        print(f"ERROR: Input file {input_file} not found!")
        sys.exit(1)
    
    # Load the combined dataset
    print(f"Loading combined dataset from {input_file}...")
    try:
        df = pd.read_csv(input_file, encoding='utf-8')
        print(f"Successfully loaded {len(df)} records with {len(df.columns)} columns")
    except Exception as e:
        print(f"ERROR loading file: {str(e)}")
        sys.exit(1)
    
    # Print all available columns for reference
    print("\nAvailable columns in the dataset:")
    for i, col in enumerate(df.columns):
        print(f"  {i+1}. {col}")
    
    # Define possible names for each key column
    column_mappings = {
        'reappointed': ['reappointed', 'reappointment', 're-appointed', 're_appointed'],
        'name': ['name', 'full_name', 'fullname', 'person_name', 'appointee'],
        'position': ['position', 'appointment', 'title', 'role', 'job_title'],
        'org': ['org', 'organization', 'organisation', 'agency', 'department', 'board']
    }
    
    # Find matching columns
    print("\nFinding key columns...")
    found_columns = {}
    missing_columns = []
    
    for key, possible_names in column_mappings.items():
        found_col = find_matching_column(df, possible_names)
        if found_col:
            found_columns[key] = found_col
            print(f"  '{key}' mapped to column: '{found_col}'")
        else:
            missing_columns.append(key)
            print(f"  WARNING: Could not find column for '{key}' (tried: {possible_names})")
    
    # Check if we have all required columns
    if missing_columns:
        print(f"\nWARNING: Missing columns: {missing_columns}")
        print("Proceeding with available columns...")
    
    # Check for year column
    year_col = find_matching_column(df, ['year', 'appointment_year', 'yr'])
    if not year_col:
        print("\nERROR: 'year' column not found in the dataset!")
        sys.exit(1)
    
    # Create new dataframe with key columns
    print("\nCreating filtered dataset...")
    columns_to_keep = []
    column_rename_map = {}
    
    # Add found columns
    for key, original_col in found_columns.items():
        columns_to_keep.append(original_col)
        column_rename_map[original_col] = key
    
    # Add year column
    columns_to_keep.append(year_col)
    if year_col != 'year':
        column_rename_map[year_col] = 'year'
    
    # Extract and rename columns
    filtered_df = df[columns_to_keep].copy()
    filtered_df = filtered_df.rename(columns=column_rename_map)
    
    # Save the filtered dataset
    print(f"\nSaving filtered dataset to {output_file}...")
    filtered_df.to_csv(output_file, index=False, encoding='utf-8')
    
    # Print summary information
    print("\n" + "="*50)
    print("FILTERED DATASET SUMMARY")
    print("="*50)
    print(f"Shape: {filtered_df.shape} (rows: {filtered_df.shape[0]}, columns: {filtered_df.shape[1]})")
    print(f"\nColumns in filtered dataset: {list(filtered_df.columns)}")
    
    # Analyze missing values
    print("\nMissing values analysis:")
    total_cells = len(filtered_df) * len(filtered_df.columns)
    total_missing = filtered_df.isnull().sum().sum()
    print(f"Total cells: {total_cells}")
    print(f"Total missing values: {total_missing} ({total_missing/total_cells*100:.2f}%)")
    
    print("\nMissing values per column:")
    for col in filtered_df.columns:
        missing_count = filtered_df[col].isnull().sum()
        missing_pct = missing_count / len(filtered_df) * 100
        print(f"  {col}: {missing_count} missing ({missing_pct:.2f}%)")
    
    # Show sample of data
    print("\nSample of filtered data (first 5 rows):")
    print(filtered_df.head())
    
    print(f"\nFiltered dataset saved successfully to: {output_file}")
    
    return filtered_df

if __name__ == "__main__":
    # Run the main function
    try:
        filtered_df = extract_key_columns()
        print("\nstep completed successfully!")
    except Exception as e:
        print(f"\nERROR: step failed with error: {str(e)}")
        sys.exit(1)