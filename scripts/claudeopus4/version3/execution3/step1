#!/usr/bin/env python3
"""
New Brunswick Government Reappointment Analysis
Analyzes which government branch most frequently reappoints past appointees
and examines trends over 2013-2024.
"""

import pandas as pd
import numpy as np
from scipy import stats
from pathlib import Path
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Set up paths
BASE_DIR = Path('.')
RAW_DATA_DIR = BASE_DIR / 'raw_data'
OUTPUT_DIR = BASE_DIR / 'scripts' / 'claudeopus4' / 'version3' / 'execution3' / 'analysis_data'

# Create output directory if it doesn't exist
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def validate_data(df, step_name):
    """Validate data integrity and print summary statistics."""
    print(f"\n{step_name} Validation:")
    print(f"  - Total rows: {len(df)}")
    print(f"  - Total columns: {len(df.columns)}")
    print(f"  - Missing values: {df.isnull().sum().sum()}")
    return df

def step1_combine_datasets():
    """Step 1: Combine the 12 raw datasets."""
    print("\n=== STEP 1: Combining 12 raw datasets ===")
    
    combined_data = []
    years_found = []
    
    for year in range(2013, 2025):
        file_path = RAW_DATA_DIR / f'appointments_{year}.csv'
        
        if file_path.exists():
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                df['year'] = year
                combined_data.append(df)
                years_found.append(year)
                print(f"  ✓ Loaded appointments_{year}.csv ({len(df)} rows)")
            except Exception as e:
                print(f"  ✗ Error loading appointments_{year}.csv: {e}")
        else:
            print(f"  ✗ File not found: appointments_{year}.csv")
    
    if not combined_data:
        raise FileNotFoundError("No appointment CSV files found in raw_data directory")
    
    combined_df = pd.concat(combined_data, ignore_index=True)
    print(f"\nCombined dataset: {len(combined_df)} total appointments from {len(years_found)} years")
    
    # Save combined dataset
    output_path = OUTPUT_DIR / 'step1_combined_appointments.csv'
    combined_df.to_csv(output_path, index=False)
    print(f"Saved to: {output_path}")
    
    return validate_data(combined_df, "Step 1")

def step2_extract_key_columns(df):
    """Step 2: Extract and retain key columns."""
    print("\n=== STEP 2: Extracting key columns ===")
    
    # Define required columns
    required_columns = ['reappointed', 'name', 'position', 'org', 'year']
    
    # Check which columns exist
    available_columns = [col for col in required_columns if col in df.columns]
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"  ⚠ Missing columns: {missing_columns}")
    
    # Extract available columns
    key_df = df[available_columns].copy()
    
    # Standardize the reappointed column if it exists
    if 'reappointed' in key_df.columns:
        # Convert to boolean if not already
        if key_df['reappointed'].dtype == 'object':
            key_df['reappointed'] = key_df['reappointed'].str.lower().isin(['true', 'yes', '1'])
        else:
            key_df['reappointed'] = key_df['reappointed'].astype(bool)
    
    # Clean text columns
    for col in ['name', 'position', 'org']:
        if col in key_df.columns:
            key_df[col] = key_df[col].fillna('').str.strip()
    
    print(f"  - Extracted {len(available_columns)} columns: {available_columns}")
    print(f"  - Unique organizations: {key_df['org'].nunique() if 'org' in key_df.columns else 'N/A'}")
    
    # Save key columns dataset
    output_path = OUTPUT_DIR / 'step2_key_columns_data.csv'
    key_df.to_csv(output_path, index=False)
    print(f"Saved to: {output_path}")
    
    return validate_data(key_df, "Step 2")

def step3_mark_repeats(df):
    """Step 3: Mark reappointed as true for repeated name-position-org combinations."""
    print("\n=== STEP 3: Marking repeated appointments ===")
    
    # Create a copy to avoid modifying original
    marked_df = df.copy()
    
    # Sort by year to ensure chronological order
    marked_df = marked_df.sort_values(['year', 'name', 'position', 'org'])
    
    # Create a composite key for tracking unique appointments
    marked_df['appointment_key'] = (marked_df['name'] + '|' + 
                                   marked_df['position'] + '|' + 
                                   marked_df['org'])
    
    # Track first appearances
    first_appearances = {}
    reappointed_count = 0
    
    # Create new reappointed column based on repeat logic
    marked_df['reappointed_calculated'] = False
    
    for idx, row in marked_df.iterrows():
        key = row['appointment_key']
        
        if key in first_appearances:
            # This is a repeat appointment
            marked_df.at[idx, 'reappointed_calculated'] = True
            reappointed_count += 1
        else:
            # First appearance
            first_appearances[key] = True
    
    # Use calculated reappointed column
    marked_df['reappointed'] = marked_df['reappointed_calculated']
    
    # Drop helper columns
    marked_df = marked_df.drop(['appointment_key', 'reappointed_calculated'], axis=1)
    
    print(f"  - Total appointments marked as reappointed: {reappointed_count}")
    print(f"  - Percentage reappointed: {(reappointed_count/len(marked_df)*100):.2f}%")
    
    # Save marked dataset
    output_path = OUTPUT_DIR / 'step3_repeats_marked.csv'
    marked_df.to_csv(output_path, index=False)
    print(f"Saved to: {output_path}")
    
    return validate_data(marked_df, "Step 3")

def step4_count_appointments(df):
    """Step 4: Count total number of appointments for each org in each year."""
    print("\n=== STEP 4: Counting appointments by organization and year ===")
    
    # Group by org and year to count total appointments
    appointment_counts = df.groupby(['year', 'org']).size().reset_index(name='total_appointments')
    
    # Sort for readability
    appointment_counts = appointment_counts.sort_values(['year', 'total_appointments'], ascending=[True, False])
    
    print(f"  - Total org-year combinations: {len(appointment_counts)}")
    print(f"  - Years covered: {appointment_counts['year'].min()} to {appointment_counts['year'].max()}")
    
    # Show top organizations by total appointments
    top_orgs = appointment_counts.groupby('org')['total_appointments'].sum().sort_values(ascending=False).head(10)
    print("\n  Top 10 organizations by total appointments (all years):")
    for org, count in top_orgs.items():
        print(f"    - {org}: {count}")
    
    # Save appointment counts
    output_path = OUTPUT_DIR / 'step4_appointment_counts.csv'
    appointment_counts.to_csv(output_path, index=False)
    print(f"\nSaved to: {output_path}")
    
    return validate_data(appointment_counts, "Step 4")

def step5_count_reappointments(df):
    """Step 5: Count reappointments for each org in each year."""
    print("\n=== STEP 5: Counting reappointments by organization and year ===")
    
    # Filter for reappointments only
    reappointments = df[df['reappointed'] == True]
    
    # Group by org and year to count reappointments
    reappointment_counts = reappointments.groupby(['year', 'org']).size().reset_index(name='reappointment_count')
    
    print(f"  - Total reappointments: {len(reappointments)}")
    print(f"  - Organizations with reappointments: {reappointment_counts['org'].nunique()}")
    
    # Show top organizations by reappointments
    top_reappoint_orgs = reappointment_counts.groupby('org')['reappointment_count'].sum().sort_values(ascending=False).head(10)
    print("\n  Top 10 organizations by total reappointments (all years):")
    for org, count in top_reappoint_orgs.items():
        print(f"    - {org}: {count}")
    
    # Save reappointment counts
    output_path = OUTPUT_DIR / 'step5_reappointment_counts.csv'
    reappointment_counts.to_csv(output_path, index=False)
    print(f"\nSaved to: {output_path}")
    
    return validate_data(reappointment_counts, "Step 5")

def step6_calculate_rates(appointment_counts, reappointment_counts):
    """Step 6: Calculate reappointment rates."""
    print("\n=== STEP 6: Calculating reappointment rates ===")
    
    # Merge appointment counts with reappointment counts
    rates_df = appointment_counts.merge(
        reappointment_counts, 
        on=['year', 'org'], 
        how='left'
    )
    
    # Fill NaN reappointment counts with 0
    rates_df['reappointment_count'] = rates_df['reappointment_count'].fillna(0)
    
    # Calculate reappointment rate
    rates_df['reappointment_rate'] = rates_df['reappointment_count'] / rates_df['total_appointments']
    
    # Sort by rate for analysis
    rates_df = rates_df.sort_values(['year', 'reappointment_rate'], ascending=[True, False])
    
    print(f"  - Organizations analyzed: {rates_df['org'].nunique()}")
    print(f"  - Average reappointment rate: {rates_df['reappointment_rate'].mean():.3f}")
    
    # Show organizations with highest average reappointment rates
    avg_rates = rates_df.groupby('org').agg({
        'reappointment_rate': 'mean',
        'total_appointments': 'sum',
        'reappointment_count': 'sum'
    }).sort_values('reappointment_rate', ascending=False)
    
    print("\n  Top 10 organizations by average reappointment rate:")
    for org in avg_rates.head(10).index:
        rate = avg_rates.loc[org, 'reappointment_rate']
        total = avg_rates.loc[org, 'total_appointments']
        reappoints = avg_rates.loc[org, 'reappointment_count']
        print(f"    - {org}: {rate:.3f} ({int(reappoints)}/{int(total)} appointments)")
    
    # Save rates
    output_path = OUTPUT_DIR / 'step6_reappointment_rates.csv'
    rates_df.to_csv(output_path, index=False)
    print(f"\nSaved to: {output_path}")
    
    return validate_data(rates_df, "Step 6")

def step7_yearly_max_rates(rates_df):
    """Step 7: Identify organization with highest reappointment rate each year."""
    print("\n=== STEP 7: Finding yearly maximum reappointment rates ===")
    
    # Filter out organizations with very few appointments to avoid noise
    min_appointments = 5
    filtered_rates = rates_df[rates_df['total_appointments'] >= min_appointments]
    
    # Find organization with highest rate for each year
    yearly_max = []
    
    for year in sorted(filtered_rates['year'].unique()):
        year_data = filtered_rates[filtered_rates['year'] == year]
        if not year_data.empty:
            max_row = year_data.loc[year_data['reappointment_rate'].idxmax()]
            yearly_max.append({
                'year': year,
                'org': max_row['org'],
                'reappointment_rate': max_row['reappointment_rate'],
                'total_appointments': max_row['total_appointments'],
                'reappointment_count': max_row['reappointment_count']
            })
    
    yearly_max_df = pd.DataFrame(yearly_max)
    
    print(f"\n  Organizations with highest reappointment rates by year (min {min_appointments} appointments):")
    for _, row in yearly_max_df.iterrows():
        print(f"    - {int(row['year'])}: {row['org']} ({row['reappointment_rate']:.3f}, "
              f"{int(row['reappointment_count'])}/{int(row['total_appointments'])} appointments)")
    
    # Count which organizations appear most frequently as yearly leaders
    org_frequency = yearly_max_df['org'].value_counts()
    print(f"\n  Most frequent yearly leaders:")
    for org, count in org_frequency.head(5).items():
        print(f"    - {org}: {count} years")
    
    # Save yearly max rates
    output_path = OUTPUT_DIR / 'step7_yearly_max_rates.csv'
    yearly_max_df.to_csv(output_path, index=False)
    print(f"\nSaved to: {output_path}")
    
    # Create visualization
    plt.figure(figsize=(12, 8))
    
    # Plot the maximum reappointment rate for each year
    plt.subplot(2, 1, 1)
    plt.plot(yearly_max_df['year'], yearly_max_df['reappointment_rate'], 'bo-', linewidth=2, markersize=8)
    plt.title('Maximum Reappointment Rate by Year', fontsize=14, fontweight='bold')
    plt.xlabel('Year')
    plt.ylabel('Reappointment Rate')
    plt.grid(True, alpha=0.3)
    
    # Add organization labels
    for _, row in yearly_max_df.iterrows():
        plt.annotate(row['org'], 
                    (row['year'], row['reappointment_rate']),
                    textcoords="offset points",
                    xytext=(0,10),
                    ha='center',
                    fontsize=8,
                    rotation=45)
    
    # Plot trend line
    z = np.polyfit(yearly_max_df['year'], yearly_max_df['reappointment_rate'], 1)
    p = np.poly1d(z)
    plt.plot(yearly_max_df['year'], p(yearly_max_df['year']), "r--", alpha=0.8, label=f'Trend: {z[0]:.4f}x + {z[1]:.2f}')
    plt.legend()
    
    plt.tight_layout()
    
    # Save plot
    plot_path = OUTPUT_DIR / 'step7_yearly_max_reappointment_rates.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Plot saved to: {plot_path}")
    
    return yearly_max_df

def step8_annual_proportions(rates_df):
    """Step 8: Compute government-wide reappointment proportion for each year."""
    print("\n=== STEP 8: Computing annual government-wide reappointment proportions ===")
    
    # Calculate annual totals
    annual_stats = rates_df.groupby('year').agg({
        'total_appointments': 'sum',
        'reappointment_count': 'sum'
    }).reset_index()
    
    # Calculate annual proportion
    annual_stats['reappointment_proportion'] = annual_stats['reappointment_count'] / annual_stats['total_appointments']
    
    print("\n  Annual reappointment proportions:")
    for _, row in annual_stats.iterrows():
        print(f"    - {int(row['year'])}: {row['reappointment_proportion']:.3f} "
              f"({int(row['reappointment_count'])}/{int(row['total_appointments'])} appointments)")
    
    # Calculate summary statistics
    print(f"\n  Summary statistics:")
    print(f"    - Mean proportion: {annual_stats['reappointment_proportion'].mean():.3f}")
    print(f"    - Std deviation: {annual_stats['reappointment_proportion'].std():.3f}")
    print(f"    - Min proportion: {annual_stats['reappointment_proportion'].min():.3f}")
    print(f"    - Max proportion: {annual_stats['reappointment_proportion'].max():.3f}")
    
    # Save annual proportions
    output_path = OUTPUT_DIR / 'step8_annual_proportions.csv'
    annual_stats.to_csv(output_path, index=False)
    print(f"\nSaved to: {output_path}")
    
    # Create visualization
    plt.figure(figsize=(12, 8))
    
    # Plot annual proportions
    plt.bar(annual_stats['year'], annual_stats['reappointment_proportion'], 
            color='steelblue', alpha=0.7, edgecolor='black')
    
    # Add value labels on bars
    for _, row in annual_stats.iterrows():
        plt.text(row['year'], row['reappointment_proportion'] + 0.002, 
                f'{row["reappointment_proportion"]:.3f}',
                ha='center', va='bottom', fontsize=10)
    
    # Add trend line
    z = np.polyfit(annual_stats['year'], annual_stats['reappointment_proportion'], 1)
    p = np.poly1d(z)
    plt.plot(annual_stats['year'], p(annual_stats['year']), "r--", 
            alpha=0.8, linewidth=2, label=f'Trend: {z[0]:.5f}x + {z[1]:.3f}')
    
    plt.title('Annual Government-Wide Reappointment Proportions', fontsize=14, fontweight='bold')
    plt.xlabel('Year')
    plt.ylabel('Reappointment Proportion')
    plt.ylim(0, annual_stats['reappointment_proportion'].max() * 1.1)
    plt.grid(True, alpha=0.3, axis='y')
    plt.legend()
    
    plt.tight_layout()
    
    # Save plot
    plot_path = OUTPUT_DIR / 'step8_annual_reappointment_proportions.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Plot saved to: {plot_path}")
    
    return annual_stats

def step9_regression_analysis(annual_stats):
    """Step 9: Run linear regression on annual reappointment proportions."""
    print("\n=== STEP 9: Linear regression analysis ===")
    
    # Prepare data for regression
    x = annual_stats['year'].values
    y = annual_stats['reappointment_proportion'].values
    
    # Perform linear regression
    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
    
    # Calculate additional statistics
    n = len(x)
    t_statistic = slope / std_err
    confidence_level = 0.95
    degrees_freedom = n - 2
    t_critical = stats.t.ppf((1 + confidence_level) / 2, degrees_freedom)
    margin_error = t_critical * std_err
    
    # Build results text
    results = []
    results.append("=== LINEAR REGRESSION ANALYSIS RESULTS ===\n")
    results.append(f"Dependent Variable: Annual Reappointment Proportion")
    results.append(f"Independent Variable: Year")
    results.append(f"Number of observations: {n}\n")
    
    results.append("REGRESSION EQUATION:")
    results.append(f"Reappointment Proportion = {slope:.6f} × Year + {intercept:.3f}\n")
    
    results.append("MODEL STATISTICS:")
    results.append(f"Slope (β₁): {slope:.6f}")
    results.append(f"Intercept (β₀): {intercept:.3f}")
    results.append(f"R-squared: {r_value**2:.4f}")
    results.append(f"Correlation coefficient (r): {r_value:.4f}")
    results.append(f"Standard error: {std_err:.6f}")
    results.append(f"T-statistic: {t_statistic:.4f}")
    results.append(f"P-value: {p_value:.6f}\n")
    
    results.append("CONFIDENCE INTERVAL (95%):")
    results.append(f"Slope: [{slope - margin_error:.6f}, {slope + margin_error:.6f}]\n")
    
    results.append("INTERPRETATION:")
    
    # Interpret trend direction
    if p_value < 0.05:
        if slope > 0:
            trend = "INCREASING"
            change_per_year = slope * 100
            results.append(f"✓ Statistically significant {trend} trend (p < 0.05)")
            results.append(f"✓ Reappointment proportion increases by {change_per_year:.3f}% per year")
        else:
            trend = "DECREASING"
            change_per_year = abs(slope) * 100
            results.append(f"✓ Statistically significant {trend} trend (p < 0.05)")
            results.append(f"✓ Reappointment proportion decreases by {change_per_year:.3f}% per year")
    else:
        results.append(f"✗ No statistically significant trend detected (p = {p_value:.4f} > 0.05)")
        results.append(f"  The reappointment proportion shows no clear trend over time")
    
    # Add effect size interpretation
    results.append(f"\nEFFECT SIZE:")
    if abs(r_value) < 0.3:
        effect = "weak"
    elif abs(r_value) < 0.5:
        effect = "moderate"
    else:
        effect = "strong"
    results.append(f"The correlation is {effect} (|r| = {abs(r_value):.3f})")
    
    # Calculate total change over period
    first_year = annual_stats['year'].min()
    last_year = annual_stats['year'].max()
    predicted_first = slope * first_year + intercept
    predicted_last = slope * last_year + intercept
    total_change = (predicted_last - predicted_first) * 100
    
    results.append(f"\nTOTAL CHANGE ({first_year}-{last_year}):")
    results.append(f"Predicted change: {total_change:+.1f} percentage points")
    results.append(f"From {predicted_first*100:.1f}% to {predicted_last*100:.1f}%")
    
    # Print results
    for line in results:
        print(f"  {line}")
    
    # Save results
    output_path = OUTPUT_DIR / 'step9_regression_results.txt'
    with open(output_path, 'w') as f:
        f.write('\n'.join(results))
    print(f"\nResults saved to: {output_path}")
    
    return {
        'slope': slope,
        'intercept': intercept,
        'r_squared': r_value**2,
        'p_value': p_value,
        'trend': trend if p_value < 0.05 else 'NO SIGNIFICANT TREND'
    }

def main():
    """Main execution function."""
    print("=" * 80)
    print("NEW BRUNSWICK GOVERNMENT REAPPOINTMENT ANALYSIS")
    print("Analyzing reappointment patterns across government branches (2013-2024)")
    print("=" * 80)
    
    try:
        # Execute analysis pipeline
        combined_df = step1_combine_datasets()
        key_df = step2_extract_key_columns(combined_df)
        marked_df = step3_mark_repeats(key_df)
        appointment_counts = step4_count_appointments(marked_df)
        reappointment_counts = step5_count_reappointments(marked_df)
        rates_df = step6_calculate_rates(appointment_counts, reappointment_counts)
        yearly_max_df = step7_yearly_max_rates(rates_df)
        annual_stats = step8_annual_proportions(rates_df)
        regression_results = step9_regression_analysis(annual_stats)
        
        # Summary findings
        print("\n" + "=" * 80)
        print("ANALYSIS COMPLETE - KEY FINDINGS:")
        print("=" * 80)
        
        # Find organization with highest overall reappointment rate
        avg_rates = rates_df.groupby('org').agg({
            'reappointment_rate': 'mean',
            'total_appointments': 'sum',
            'reappointment_count': 'sum'
        }).sort_values('reappointment_rate', ascending=False)
        
        # Filter for organizations with substantial appointments
        significant_orgs = avg_rates[avg_rates['total_appointments'] >= 50]
        
        if not significant_orgs.empty:
            top_org = significant_orgs.index[0]
            top_rate = significant_orgs.loc[top_org, 'reappointment_rate']
            top_total = significant_orgs.loc[top_org, 'total_appointments']
            
            print(f"\n1. ORGANIZATION WITH HIGHEST REAPPOINTMENT RATE:")
            print(f"   → {top_org}")
            print(f"   → Average rate: {top_rate:.3f} ({int(top_total)} total appointments)")
        
        print(f"\n2. TREND ANALYSIS:")
        print(f"   → Overall trend: {regression_results['trend']}")
        if regression_results['p_value'] < 0.05:
            print(f"   → Annual change: {regression_results['slope']*100:+.3f}% per year")
        print(f"   → Statistical significance: p = {regression_results['p_value']:.6f}")
        
        print("\n" + "=" * 80)
        print(f"All results saved to: {OUTPUT_DIR}")
        print("=" * 80)
        
    except Exception as e:
        print(f"\n✗ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())