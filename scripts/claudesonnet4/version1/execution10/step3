#!/usr/bin/env python3
"""
New Brunswick Government Appointments - Reappointments Marker

This script identifies and marks reappointments based on unique combinations
of name, position, and organization, using chronological ordering.

Author: Claude Sonnet 4
Date: 2025-06-30
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys
import re
from difflib import SequenceMatcher

def normalize_name(name):
    """
    Normalize a name for better matching by handling common variations.
    
    Args:
        name (str): Original name string
        
    Returns:
        str: Normalized name string
    """
    
    if pd.isna(name) or not isinstance(name, str):
        return str(name) if not pd.isna(name) else ""
    
    # Convert to lowercase and strip whitespace
    normalized = name.lower().strip()
    
    # Remove common prefixes and suffixes
    prefixes = ['dr.', 'dr', 'mr.', 'mr', 'mrs.', 'mrs', 'ms.', 'ms', 'prof.', 'prof']
    suffixes = ['jr.', 'jr', 'sr.', 'sr', 'ii', 'iii', 'iv', 'phd', 'md', 'qc', 'q.c.']
    
    words = normalized.split()
    
    # Remove prefixes
    if words and words[0] in prefixes:
        words = words[1:]
    
    # Remove suffixes
    if words and words[-1] in suffixes:
        words = words[:-1]
    
    # Rejoin and normalize spaces
    normalized = ' '.join(words)
    
    # Remove extra punctuation and normalize spaces
    normalized = re.sub(r'[^\w\s-]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized)
    
    return normalized.strip()

def normalize_organization(org):
    """
    Normalize organization name for better matching.
    
    Args:
        org (str): Original organization string
        
    Returns:
        str: Normalized organization string
    """
    
    if pd.isna(org) or not isinstance(org, str):
        return str(org) if not pd.isna(org) else ""
    
    # Convert to lowercase and strip
    normalized = org.lower().strip()
    
    # Common organization name variations
    replacements = {
        'department of': 'dept of',
        'ministry of': 'min of',
        'commission': 'comm',
        'corporation': 'corp',
        'authority': 'auth',
        'government of new brunswick': 'gnb',
        'new brunswick': 'nb'
    }
    
    for old, new in replacements.items():
        normalized = normalized.replace(old, new)
    
    # Remove extra spaces and punctuation
    normalized = re.sub(r'[^\w\s-]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized)
    
    return normalized.strip()

def normalize_position(position):
    """
    Normalize position title for better matching.
    
    Args:
        position (str): Original position string
        
    Returns:
        str: Normalized position string
    """
    
    if pd.isna(position) or not isinstance(position, str):
        return str(position) if not pd.isna(position) else ""
    
    # Convert to lowercase and strip
    normalized = position.lower().strip()
    
    # Common position variations
    replacements = {
        'chairperson': 'chair',
        'vice-chairperson': 'vice-chair',
        'vice chairperson': 'vice-chair',
        'member': 'member',
        'director': 'dir',
        'executive': 'exec'
    }
    
    for old, new in replacements.items():
        normalized = normalized.replace(old, new)
    
    # Remove extra spaces and punctuation
    normalized = re.sub(r'[^\w\s-]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized)
    
    return normalized.strip()

def load_step2_data():
    """
    Load the dataset from step 2.
    
    Returns:
        pd.DataFrame: Dataset with key columns
    """
    
    # Define input path
    input_path = Path("scripts/claudesonnet4/version1/execution10/analysis_data/step2_key_columns_data.csv")
    
    # Check if input file exists
    if not input_path.exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")
    
    print("Loading key columns dataset...")
    print("=" * 50)
    
    try:
        # Load the dataset
        df = pd.read_csv(input_path)
        print(f"Loaded dataset with shape: {df.shape}")
        
        # Validate required columns
        required_columns = ['name', 'position', 'org', 'year']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"Missing required columns: {missing_columns}")
        
        # Ensure year is numeric
        if 'year' in df.columns:
            df.loc[:, 'year'] = pd.to_numeric(df['year'], errors='coerce')
        
        # Initialize reappointed column if it doesn't exist
        if 'reappointed' not in df.columns:
            df.loc[:, 'reappointed'] = False
            print("Added 'reappointed' column initialized to False")
        
        return df
        
    except Exception as e:
        raise Exception(f"Error loading dataset: {str(e)}")

def identify_reappointments(df):
    """
    Identify and mark reappointments based on name, position, and organization.
    
    Args:
        df (pd.DataFrame): Input dataset
        
    Returns:
        pd.DataFrame: Updated dataset with reappointments marked
    """
    
    print(f"\nIdentifying reappointments...")
    print("-" * 30)
    
    # Create a copy to avoid modifying original
    df_updated = df.copy()
    
    # Add normalized columns for better matching
    df_updated.loc[:, 'name_normalized'] = df_updated['name'].apply(normalize_name)
    df_updated.loc[:, 'position_normalized'] = df_updated['position'].apply(normalize_position)
    df_updated.loc[:, 'org_normalized'] = df_updated['org'].apply(normalize_organization)
    
    # Create a unique identifier for each person-position-organization combination
    df_updated.loc[:, 'unique_combo'] = (
        df_updated['name_normalized'] + '|' + 
        df_updated['position_normalized'] + '|' + 
        df_updated['org_normalized']
    )
    
    # Track statistics
    original_reappointments = df_updated['reappointed'].sum() if 'reappointed' in df_updated.columns else 0
    new_reappointments = 0
    total_groups = 0
    groups_with_reappointments = 0
    
    # Group by unique combination
    grouped = df_updated.groupby('unique_combo')
    
    print(f"Found {len(grouped)} unique person-position-organization combinations")
    
    # Process each group
    for combo, group in grouped:
        total_groups += 1
        
        # Skip if only one occurrence
        if len(group) <= 1:
            continue
        
        # Skip if all values are missing/empty
        if not combo or combo.count('|') != 2:
            continue
        
        # Sort by year (chronologically) - handle missing years
        group_sorted = group.sort_values(['year'], kind='stable', na_position='last')
        
        # Get indices for all but the first occurrence
        indices_to_mark = group_sorted.index.tolist()[1:]
        
        if indices_to_mark:
            groups_with_reappointments += 1
            
            # Mark as reappointments
            for idx in indices_to_mark:
                if not df_updated.loc[idx, 'reappointed']:
                    df_updated.loc[idx, 'reappointed'] = True
                    new_reappointments += 1
            
            # Print details for verification (first few groups)
            if groups_with_reappointments <= 5:
                name = group_sorted['name'].iloc[0]
                position = group_sorted['position'].iloc[0]
                org = group_sorted['org'].iloc[0]
                years = group_sorted['year'].tolist()
                
                print(f"  Group {groups_with_reappointments}: {name} | {position} | {org}")
                print(f"    Years: {years} -> Marked {len(indices_to_mark)} reappointments")
    
    # Remove temporary columns
    df_updated = df_updated.drop(['name_normalized', 'position_normalized', 'org_normalized', 'unique_combo'], axis=1)
    
    # Print statistics
    print(f"\nReappointment Identification Statistics:")
    print("=" * 45)
    print(f"Total unique combinations analyzed: {total_groups:,}")
    print(f"Combinations with multiple occurrences: {groups_with_reappointments:,}")
    print(f"Original reappointments in dataset: {original_reappointments:,}")
    print(f"New reappointments identified: {new_reappointments:,}")
    
    final_reappointments = df_updated['reappointed'].sum()
    print(f"Total reappointments after processing: {final_reappointments:,}")
    
    if len(df_updated) > 0:
        reapp_percentage = (final_reappointments / len(df_updated)) * 100
        print(f"Percentage of all appointments that are reappointments: {reapp_percentage:.1f}%")
    
    return df_updated

def analyze_reappointments(df):
    """
    Analyze the reappointment patterns in the dataset.
    
    Args:
        df (pd.DataFrame): Dataset with reappointments marked
    """
    
    print(f"\nReappointment Analysis:")
    print("=" * 25)
    
    # Basic statistics
    total_records = len(df)
    reappointments = df['reappointed'].sum()
    first_appointments = total_records - reappointments
    
    print(f"Total appointments: {total_records:,}")
    print(f"First appointments: {first_appointments:,} ({(first_appointments/total_records)*100:.1f}%)")
    print(f"Reappointments: {reappointments:,} ({(reappointments/total_records)*100:.1f}%)")
    
    # Reappointments by year
    if 'year' in df.columns:
        print(f"\nReappointments by year:")
        yearly_reapp = df.groupby('year')['reappointed'].agg(['count', 'sum']).reset_index()
        yearly_reapp.columns = ['year', 'total_appointments', 'reappointments']
        yearly_reapp['reappointment_rate'] = (yearly_reapp['reappointments'] / yearly_reapp['total_appointments']) * 100
        
        for _, row in yearly_reapp.iterrows():
            year = int(row['year']) if not pd.isna(row['year']) else 'Unknown'
            total = int(row['total_appointments'])
            reapp = int(row['reappointments'])
            rate = row['reappointment_rate']
            print(f"  {year}: {reapp:,}/{total:,} ({rate:.1f}%)")
    
    # Check for data quality issues
    print(f"\nData Quality Check:")
    print("-" * 20)
    
    missing_names = df['name'].isna().sum()
    missing_positions = df['position'].isna().sum()
    missing_orgs = df['org'].isna().sum()
    missing_years = df['year'].isna().sum()
    
    print(f"Missing names: {missing_names:,}")
    print(f"Missing positions: {missing_positions:,}")
    print(f"Missing organizations: {missing_orgs:,}")
    print(f"Missing years: {missing_years:,}")

def save_updated_dataset(df):
    """
    Save the updated dataset with reappointments marked.
    
    Args:
        df (pd.DataFrame): Updated dataset
    """
    
    # Define output path
    output_path = Path("scripts/claudesonnet4/version1/execution10/analysis_data/step3_repeats_marked.csv")
    
    try:
        # Save the dataset
        df.to_csv(output_path, index=False)
        print(f"\nUpdated dataset saved to: {output_path}")
        print(f"File size: {output_path.stat().st_size / 1024:.1f} KB")
        
    except Exception as e:
        raise Exception(f"Error saving dataset: {str(e)}")

def main():
    """Main execution function."""
    
    print("New Brunswick Appointments - Reappointments Marker")
    print("=" * 60)
    
    try:
        # Load step 2 data
        df = load_step2_data()
        
        # Identify and mark reappointments
        df_updated = identify_reappointments(df)
        
        # Analyze reappointment patterns
        analyze_reappointments(df_updated)
        
        # Save updated dataset
        save_updated_dataset(df_updated)
        
        print(f"\nScript completed successfully!")
        
    except Exception as e:
        print(f"\nERROR: Script failed with error: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()