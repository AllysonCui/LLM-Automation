#!/usr/bin/env python3
"""
New Brunswick Government Appointments Data Combiner

This script loads all CSV files containing New Brunswick government appointment data 
from 2013-2024, adds year columns, combines them into a single dataset, and saves 
the result for further analysis.

Author: Claude Sonnet 4
Version: 1.0
Execution: 5
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys

def main():
    """Main function to load, combine, and save appointment data."""
    
    # Define paths
    script_dir = Path(__file__).parent
    raw_data_dir = script_dir / "raw_data"
    analysis_data_dir = script_dir / "analysis_data"
    
    # Create analysis_data directory if it doesn't exist
    analysis_data_dir.mkdir(parents=True, exist_ok=True)
    
    # Years to process
    years = range(2013, 2025)  # 2013 through 2024
    
    # List to store individual DataFrames
    dataframes = []
    
    print("Loading New Brunswick government appointment data...")
    print("-" * 50)
    
    # Load each year's data
    for year in years:
        filename = f"raw_data/appointments_{year}.csv"
        filepath = Path(filename)
        
        try:
            # Check if file exists
            if not filepath.exists():
                print(f"WARNING: File {filename} not found, skipping...")
                continue
                
            # Load CSV file
            df = pd.read_csv(filepath)
            
            # Add year column
            df['year'] = year
            
            # Append to list
            dataframes.append(df)
            
            print(f"✓ Loaded {filename}: {df.shape[0]} rows, {df.shape[1]} columns")
            
        except Exception as e:
            print(f"ERROR loading {filename}: {str(e)}")
            continue
    
    # Check if we successfully loaded any data
    if not dataframes:
        print("ERROR: No data files were successfully loaded!")
        sys.exit(1)
    
    print(f"\nSuccessfully loaded {len(dataframes)} files")
    print("-" * 50)
    
    try:
        # Combine all DataFrames
        print("Combining datasets...")
        combined_df = pd.concat(dataframes, ignore_index=True)
        
        # Sort by year for better organization
        combined_df = combined_df.sort_values(['year', 'posted_date'], na_position='last')
        combined_df = combined_df.reset_index(drop=True)
        
        # Save combined dataset
        output_file = analysis_data_dir / "step1_combined_appointments.csv"
        combined_df.to_csv(output_file, index=False)
        
        print(f"✓ Combined dataset saved to: {output_file}")
        print("-" * 50)
        
        # Print dataset information
        print("COMBINED DATASET SUMMARY:")
        print(f"Shape: {combined_df.shape} (rows, columns)")
        print(f"Total appointments: {combined_df.shape[0]:,}")
        print(f"Years covered: {combined_df['year'].min()} - {combined_df['year'].max()}")
        print(f"Memory usage: {combined_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        print("\nColumn Information:")
        print("-" * 30)
        for col in combined_df.columns:
            non_null = combined_df[col].notna().sum()
            null_count = combined_df[col].isna().sum()
            dtype = str(combined_df[col].dtype)
            print(f"{col:15} | {dtype:10} | {non_null:6} non-null | {null_count:6} null")
        
        print("\nYear Distribution:")
        print("-" * 20)
        year_counts = combined_df['year'].value_counts().sort_index()
        for year, count in year_counts.items():
            print(f"{year}: {count:4} appointments")
        
        print("\nData combination completed successfully!")
        
    except Exception as e:
        print(f"ERROR during data combination: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()