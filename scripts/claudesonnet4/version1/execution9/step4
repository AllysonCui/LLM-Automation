#!/usr/bin/env python3
"""
New Brunswick Government Appointments Count Summary
Creates a pivot table of appointment counts by organization and year.
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys

def main():
    """Main function to create appointment counts summary."""
    
    # Define paths
    script_dir = Path(__file__).parent
    analysis_data_dir = script_dir / "analysis_data"
    input_file = analysis_data_dir / "step3_repeats_marked.csv"
    output_file = analysis_data_dir / "step4_appointment_counts.csv"
    
    # Check if input file exists
    if not input_file.exists():
        print(f"✗ Error: Input file not found - {input_file}")
        print("Please ensure step3_repeats_marked.csv exists in the analysis_data directory")
        sys.exit(1)
    
    try:
        # Load the dataset
        print(f"Loading dataset from: {input_file}")
        df = pd.read_csv(input_file)
        print(f"✓ Loaded dataset: {df.shape[0]:,} rows, {df.shape[1]} columns")
        
        # Validate required columns
        required_columns = ['org', 'year']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"✗ Error: Missing required columns: {missing_columns}")
            sys.exit(1)
        
        # Data quality assessment
        print("\nData quality assessment:")
        initial_rows = len(df)
        
        # Check for missing values in key columns
        missing_org = df['org'].isna().sum()
        missing_year = df['year'].isna().sum()
        
        print(f"  Missing organization values: {missing_org:,}")
        print(f"  Missing year values: {missing_year:,}")
        
        # Remove rows with missing org or year
        df_clean = df.dropna(subset=['org', 'year']).copy()
        removed_rows = initial_rows - len(df_clean)
        
        if removed_rows > 0:
            print(f"  ⚠ Removed {removed_rows:,} rows with missing org/year data")
        
        # Validate year data type and range
        try:
            df_clean['year'] = pd.to_numeric(df_clean['year'], errors='coerce')
            
            # Remove rows where year conversion failed
            year_na_after_conversion = df_clean['year'].isna().sum()
            if year_na_after_conversion > 0:
                print(f"  ⚠ Found {year_na_after_conversion:,} invalid year values")
                df_clean = df_clean.dropna(subset=['year'])
            
            # Convert year to integer
            df_clean['year'] = df_clean['year'].astype(int)
            
        except Exception as e:
            print(f"✗ Error processing year column: {e}")
            sys.exit(1)
        
        # Validate year range (reasonable years for government appointments)
        min_year = df_clean['year'].min()
        max_year = df_clean['year'].max()
        
        print(f"  Year range: {min_year} to {max_year}")
        
        # Flag potentially problematic years
        current_year = 2024  # Based on the data context
        if min_year < 1900 or max_year > current_year + 1:
            print(f"  ⚠ Warning: Unusual year range detected")
        
        # Clean organization names
        df_clean['org'] = df_clean['org'].astype(str).str.strip()
        
        # Remove empty organization names
        empty_orgs = (df_clean['org'] == '') | (df_clean['org'] == 'nan')
        if empty_orgs.sum() > 0:
            print(f"  ⚠ Removed {empty_orgs.sum():,} rows with empty organization names")
            df_clean = df_clean[~empty_orgs]
        
        final_rows = len(df_clean)
        print(f"  Final dataset: {final_rows:,} rows ({(final_rows/initial_rows)*100:.1f}% of original)")
        
        # Group by organization and year, count appointments
        print("\nCreating appointment counts by organization and year...")
        counts = df_clean.groupby(['org', 'year']).size().reset_index(name='appointments')
        
        print(f"✓ Generated {len(counts):,} organization-year combinations")
        
        # Create pivot table with organizations as rows and years as columns
        pivot_table = counts.pivot(index='org', columns='year', values='appointments')
        
        # Fill missing values with 0 (no appointments for that org in that year)
        pivot_table = pivot_table.fillna(0).astype(int)
        
        # Add total column
        pivot_table['Total'] = pivot_table.sum(axis=1)
        
        # Add total row
        total_row = pivot_table.sum(axis=0)
        total_row.name = 'TOTAL'
        pivot_table = pd.concat([pivot_table, total_row.to_frame().T])
        
        # Save the pivot table
        pivot_table.to_csv(output_file)
        print(f"✓ Saved appointment counts to: {output_file}")
        
        # Print summary statistics
        print("\n" + "="*70)
        print("APPOINTMENT COUNTS SUMMARY")
        print("="*70)
        
        # Exclude the TOTAL row for organization statistics
        org_data = pivot_table.drop('TOTAL', errors='ignore')
        
        print(f"Total organizations: {len(org_data):,}")
        print(f"Year range: {pivot_table.columns[0]} to {pivot_table.columns[-2]}")  # Exclude 'Total' column
        print(f"Total appointments: {org_data['Total'].sum():,}")
        
        # Top organizations by total appointments
        print("\nTop 10 organizations by total appointments:")
        top_orgs = org_data.nlargest(10, 'Total')
        for i, (org, row) in enumerate(top_orgs.iterrows(), 1):
            print(f"  {i:2d}. {org}: {row['Total']:,} appointments")
        
        # Organizations with appointments in multiple years
        years_cols = [col for col in org_data.columns if col != 'Total']
        active_years = (org_data[years_cols] > 0).sum(axis=1)
        multi_year_orgs = (active_years > 1).sum()
        
        print(f"\nOrganizations active in multiple years: {multi_year_orgs:,}")
        print(f"Average years per organization: {active_years.mean():.1f}")
        
        # Year with most appointments
        year_totals = org_data[years_cols].sum(axis=0)
        peak_year = year_totals.idxmax()
        peak_count = year_totals.max()
        
        print(f"Year with most appointments: {peak_year} ({peak_count:,} appointments)")
        
        # Show the pivot table (first few rows and columns for readability)
        print(f"\nAppointment counts table (showing first 10 organizations):")
        display_cols = years_cols[:6] + ['Total'] if len(years_cols) > 6 else years_cols + ['Total']
        display_table = org_data.head(10)[display_cols]
        
        print(display_table.to_string())
        
        if len(org_data) > 10:
            print(f"\n... and {len(org_data) - 10} more organizations")
        
        # Data validation checks
        print(f"\nData validation:")
        print(f"  ✓ All counts are non-negative: {(org_data >= 0).all().all()}")
        print(f"  ✓ Row totals match sum of years: {(org_data['Total'] == org_data[years_cols].sum(axis=1)).all()}")
        
        # Check for unusually high counts that might indicate data issues
        max_count = org_data[years_cols].max().max()
        if max_count > 1000:
            print(f"  ⚠ Warning: Very high appointment count detected ({max_count:,})")
        else:
            print(f"  ✓ Maximum single year count: {max_count:,} (reasonable)")
        
        print("\n✓ Appointment counts analysis completed successfully!")
        
    except Exception as e:
        print(f"✗ Error processing dataset: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()