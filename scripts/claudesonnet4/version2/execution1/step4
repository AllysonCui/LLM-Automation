#!/usr/bin/env python3
"""
Step 4: Appointment Counts by Organization and Year
New Brunswick Government Appointments Analysis

This script counts the total number of appointments (appointees) for each 
organization in each year.

Research Question: Which government branch in New Brunswick most frequently 
reappoints past appointees, and is this trend increasing or declining over the past 12 years?
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

def create_output_directories():
    """Create necessary output directories if they don't exist."""
    output_dir = Path("scripts/claudesonnet4/version2/execution1/analysis_data")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ Created output directory: {output_dir}")
    return output_dir

def load_marked_dataset():
    """
    Load the dataset with marked repeats from step 3.
    
    Returns:
        pd.DataFrame: Dataset with marked repeats
    """
    # Try multiple possible input locations
    input_paths = [
        Path("scripts/claudesonnet4/version2/execution1/analysis_data/step3_repeats_marked.csv"),
        Path("scripts/gpt4o/version2/execution4/analysis_data/step3_repeats_marked.csv"),
        Path("step3_repeats_marked.csv")
    ]
    
    for input_path in input_paths:
        if input_path.exists():
            try:
                df = pd.read_csv(input_path, encoding='utf-8')
                print(f"âœ“ Loaded marked dataset from: {input_path}")
                print(f"   Dataset shape: {df.shape[0]:,} rows, {df.shape[1]} columns")
                return df
            except Exception as e:
                print(f"âŒ Error loading {input_path}: {e}")
                continue
    
    print("âŒ Error: Could not find step3_repeats_marked.csv")
    print("   Please ensure Step 3 has been completed successfully")
    sys.exit(1)

def validate_required_columns(df):
    """
    Validate that all required columns are present.
    
    Args:
        df (pd.DataFrame): Input dataframe
    
    Returns:
        bool: True if all required columns are present
    """
    required_columns = ['org', 'year']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"âŒ Error: Missing required columns: {missing_columns}")
        print(f"   Available columns: {list(df.columns)}")
        return False
    
    print(f"âœ“ All required columns present for counting: {required_columns}")
    return True

def clean_organization_names(df):
    """
    Clean and standardize organization names for consistent counting.
    
    Args:
        df (pd.DataFrame): Input dataframe
    
    Returns:
        pd.DataFrame: Dataframe with cleaned organization names
    """
    df_clean = df.copy()
    
    # Clean organization names
    if 'org' in df_clean.columns:
        # Store original org names for comparison
        original_orgs = df_clean['org'].unique()
        
        # Convert to string and handle nulls
        df_clean['org'] = df_clean['org'].fillna('Unknown Organization').astype(str)
        
        # Standardize organization names
        df_clean['org'] = (df_clean['org']
                          .str.strip()
                          .str.replace(r'\s+', ' ', regex=True))
        
        # Handle common variations and abbreviations
        org_replacements = {
            'unknown organization': 'Unknown Organization',
            'n/a': 'Unknown Organization',
            'na': 'Unknown Organization',
            'none': 'Unknown Organization',
            '': 'Unknown Organization'
        }
        
        df_clean['org'] = df_clean['org'].replace(org_replacements)
        
        # Report on cleaning
        cleaned_orgs = df_clean['org'].unique()
        print(f"âœ“ Cleaned organization names")
        print(f"   Original unique organizations: {len(original_orgs):,}")
        print(f"   Cleaned unique organizations: {len(cleaned_orgs):,}")
        
        if len(original_orgs) != len(cleaned_orgs):
            print(f"   Standardization reduced organizations by: {len(original_orgs) - len(cleaned_orgs):,}")
    
    return df_clean

def validate_year_data(df):
    """
    Validate and clean year data.
    
    Args:
        df (pd.DataFrame): Input dataframe
    
    Returns:
        pd.DataFrame: Dataframe with validated years
    """
    df_clean = df.copy()
    
    # Check year column
    if 'year' in df_clean.columns:
        # Convert to numeric and handle errors
        df_clean['year'] = pd.to_numeric(df_clean['year'], errors='coerce')
        
        # Check for null years
        null_years = df_clean['year'].isna().sum()
        if null_years > 0:
            print(f"âš ï¸  Warning: {null_years:,} rows with missing/invalid years")
            # Remove rows with null years for counting purposes
            df_clean = df_clean.dropna(subset=['year'])
            print(f"   Removed rows with null years, remaining: {len(df_clean):,} rows")
        
        # Check year range
        min_year = df_clean['year'].min()
        max_year = df_clean['year'].max()
        print(f"âœ“ Year data validated")
        print(f"   Year range: {int(min_year)} - {int(max_year)}")
        
        # Check for unreasonable years
        expected_years = set(range(2013, 2025))
        actual_years = set(df_clean['year'].astype(int).unique())
        unexpected_years = actual_years - expected_years
        
        if unexpected_years:
            print(f"âš ï¸  Warning: Unexpected years found: {sorted(unexpected_years)}")
    
    return df_clean

def count_appointments_by_org_year(df):
    """
    Count total appointments for each organization in each year.
    
    Args:
        df (pd.DataFrame): Input dataframe
    
    Returns:
        pd.DataFrame: Appointment counts by organization and year
    """
    print(f"\nğŸ“Š Counting appointments by organization and year...")
    
    # Group by organization and year, count appointments
    appointment_counts = (df.groupby(['org', 'year'])
                      .size()
                      .reset_index(name='appointment_count'))
    
    # Sort by organization and year
    appointment_counts = appointment_counts.sort_values(['org', 'year']).reset_index(drop=True)
    
    print(f"âœ“ Appointment counting completed")
    print(f"   Total org-year combinations: {len(appointment_counts):,}")
    print(f"   Organizations: {appointment_counts['org'].nunique():,}")
    print(f"   Years covered: {sorted(appointment_counts['year'].unique())}")
    
    return appointment_counts

def analyze_appointment_count_patterns(appointment_counts):
    """
    Analyze patterns in appointment counts across organizations and years.
    
    Args:
        appointment_counts (pd.DataFrame): Appointment counts by org and year
    """
    print(f"\nğŸ“ˆ Analyzing Appointment Count Patterns:")
    
    # Summary statistics
    total_appointments = appointment_counts['appointment_count'].sum()
    avg_appointments_per_org_year = appointment_counts['appointment_count'].mean()
    
    print(f"   Total appointments across all org-years: {total_appointments:,}")
    print(f"   Average appointments per org-year: {avg_appointments_per_org_year:.1f}")
    print(f"   Min appointments in org-year: {appointment_counts['appointment_count'].min()}")
    print(f"   Max appointments in org-year: {appointment_counts['appointment_count'].max()}")
    
    # Top organizations by total appointments
    org_totals = (appointment_counts.groupby('org')['appointment_count']
                 .sum()
                 .sort_values(ascending=False))
    
    print(f"\nğŸ“Š Top 15 Organizations by Total Appointments (2013-2024):")
    for org, total in org_totals.head(15).items():
        years_active = appointment_counts[appointment_counts['org'] == org]['year'].nunique()
        avg_per_year = total / years_active
        print(f"   {org}: {total:,} appointments ({years_active} years, {avg_per_year:.1f} avg/year)")
    
    # Annual totals across all organizations
    annual_totals = (appointment_counts.groupby('year')['appointment_count']
                    .sum()
                    .sort_index())
    
    print(f"\nğŸ“Š Annual Appointment Totals Across All Organizations:")
    for year, total in annual_totals.items():
        orgs_active = appointment_counts[appointment_counts['year'] == year]['org'].nunique()
        print(f"   {int(year)}: {total:,} appointments across {orgs_active:,} organizations")
    
    # Organizations with most consistent activity (present in most years)
    org_year_counts = appointment_counts.groupby('org')['year'].nunique().sort_values(ascending=False)
    total_years = appointment_counts['year'].nunique()
    
    print(f"\nğŸ“Š Most Consistently Active Organizations:")
    print(f"   (Organizations present in most years, total years available: {total_years})")
    for org, year_count in org_year_counts.head(10).items():
        consistency_pct = (year_count / total_years) * 100
        total_appointments = org_totals[org]
        print(f"   {org}: {year_count}/{total_years} years ({consistency_pct:.1f}%), "
              f"{total_appointments:,} total appointments")
    
    # Year-over-year growth analysis
    print(f"\nğŸ“Š Year-over-Year Total Appointment Changes:")
    annual_totals_list = annual_totals.tolist()
    years_list = annual_totals.index.tolist()
    
    for i in range(1, len(annual_totals_list)):
        current_year = int(years_list[i])
        previous_year = int(years_list[i-1])
        current_total = annual_totals_list[i]
        previous_total = annual_totals_list[i-1]
        
        change = current_total - previous_total
        change_pct = (change / previous_total) * 100 if previous_total > 0 else 0
        
        change_direction = "â†—ï¸" if change > 0 else "â†˜ï¸" if change < 0 else "â†’"
        print(f"   {previous_year} â†’ {current_year}: {previous_total:,} â†’ {current_total:,} "
              f"({change:+,}, {change_pct:+.1f}%) {change_direction}")

def create_pivot_table(appointment_counts):
    """
    Create a pivot table showing appointment counts by organization and year.
    
    Args:
        appointment_counts (pd.DataFrame): Appointment counts by org and year
    
    Returns:
        pd.DataFrame: Pivot table with years as columns and orgs as rows
    """
    print(f"\nğŸ”„ Creating pivot table (org Ã— year)...")
    
    # Create pivot table
    pivot_table = appointment_counts.pivot(index='org', columns='year', values='appointment_count')
    
    # Fill missing values with 0 (organization had no appointments that year)
    pivot_table = pivot_table.fillna(0).astype(int)
    
    # Add total column
    pivot_table['Total'] = pivot_table.sum(axis=1)
    
    # Sort by total appointments (descending)
    pivot_table = pivot_table.sort_values('Total', ascending=False)
    
    print(f"âœ“ Pivot table created")
    print(f"   Dimensions: {pivot_table.shape[0]:,} organizations Ã— {pivot_table.shape[1]:,} columns")
    print(f"   Years covered: {sorted([col for col in pivot_table.columns if col != 'Total'])}")
    
    return pivot_table

def count_appointments():
    """
    Main function to count appointments by organization and year.
    
    Returns:
        tuple: (appointment_counts DataFrame, pivot_table DataFrame)
    """
    print("=" * 60)
    print("STEP 4: COUNTING EMPLOYEES BY ORGANIZATION AND YEAR")
    print("=" * 60)
    
    # Create output directory
    output_dir = create_output_directories()
    
    # Load marked dataset
    print(f"\nğŸ“ Loading marked dataset...")
    df = load_marked_dataset()
    
    # Validate required columns
    if not validate_required_columns(df):
        sys.exit(1)
    
    # Show initial statistics
    print(f"\nğŸ“Š Initial Dataset Statistics:")
    print(f"   Total appointments: {len(df):,}")
    print(f"   Organizations: {df['org'].nunique():,}")
    print(f"   Years: {sorted(df['year'].unique())}")
    
    # Clean organization names
    df_clean = clean_organization_names(df)
    
    # Validate year data
    df_clean = validate_year_data(df_clean)
    
    # Count appointments by organization and year
    appointment_counts = count_appointments_by_org_year(df_clean)
    
    # Analyze patterns
    analyze_appointment_count_patterns(appointment_counts)
    
    # Create pivot table for easy analysis
    pivot_table = create_pivot_table(appointment_counts)
    
    # Show sample of results
    print(f"\nğŸ“‹ Sample Appointment Counts (Top 10 Organizations):")
    sample_counts = appointment_counts.merge(
        appointment_counts.groupby('org')['appointment_count'].sum().reset_index().rename(columns={'appointment_count': 'total'}),
        on='org'
    ).sort_values(['total', 'org', 'year'], ascending=[False, True, True]).head(20)
    
    for _, row in sample_counts.iterrows():
        print(f"   {row['org']} ({int(row['year'])}): {row['appointment_count']:,} appointments")
    
    return appointment_counts, pivot_table

def save_appointment_counts(appointment_counts, pivot_table, output_dir):
    """
    Save the appointment counts and pivot table to CSV files.
    
    Args:
        appointment_counts (pd.DataFrame): Appointment counts by org and year
        pivot_table (pd.DataFrame): Pivot table of appointment counts
        output_dir (Path): Output directory
    """
    try:
        # Save main appointment counts
        output_file = output_dir / "step4_appointment_counts.csv"
        appointment_counts.to_csv(output_file, index=False, encoding='utf-8')
        print(f"âœ“ Saved appointment counts to: {output_file}")
        print(f"   File size: {output_file.stat().st_size / 1024:.1f} KB")
        
        # Save pivot table for easier analysis
        pivot_file = output_dir / "step4_appointment_counts_pivot.csv"
        pivot_table.to_csv(pivot_file, encoding='utf-8')
        print(f"âœ“ Saved pivot table to: {pivot_file}")
        print(f"   File size: {pivot_file.stat().st_size / 1024:.1f} KB")
        
        # Verify the saved files
        verification_df = pd.read_csv(output_file)
        if len(verification_df) == len(appointment_counts):
            print(f"âœ“ File verification successful: {len(verification_df):,} rows")
        else:
            print(f"âš ï¸  Warning: Row count mismatch in saved file")
            
    except Exception as e:
        print(f"âŒ Error saving appointment counts: {e}")
        sys.exit(1)

def main():
    """Main execution function."""
    try:
        # Count appointments by organization and year
        appointment_counts, pivot_table = count_appointments()
        
        # Create output directory
        output_dir = Path("scripts/claudesonnet4/version2/execution1/analysis_data")
        
        # Save results
        save_appointment_counts(appointment_counts, pivot_table, output_dir)
        
        print("\n" + "=" * 60)
        print("STEP 4 COMPLETED SUCCESSFULLY")
        print("=" * 60)
        print(f"âœ… Counted appointments for {appointment_counts['org'].nunique():,} organizations across {appointment_counts['year'].nunique():,} years")
        print(f"âœ… Total org-year combinations: {len(appointment_counts):,}")
        print(f"âœ… Main output saved to: step4_appointment_counts.csv")
        print(f"âœ… Pivot table saved to: step4_appointment_counts_pivot.csv")
        print(f"âœ… Ready for Step 5: Reappointment count analysis")
        
    except KeyboardInterrupt:
        print(f"\nâŒ Process interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Unexpected error in main execution: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()