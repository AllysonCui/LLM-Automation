#!/usr/bin/env python3
"""
Step 2: Extract and retain key columns
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script extracts the key columns needed for analysis: 
"reappointed", "name", "position", "org", and "year"
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

def setup_directories():
    """Create necessary directories for the analysis."""
    base_dir = Path("scripts/claudesonnet4/version2/execution10")
    analysis_dir = base_dir / "analysis_data"
    
    # Create directories if they don't exist
    base_dir.mkdir(parents=True, exist_ok=True)
    analysis_dir.mkdir(parents=True, exist_ok=True)
    
    return base_dir, analysis_dir

def validate_input_file(file_path):
    """Check if input file exists and provide informative error message."""
    if not file_path.exists():
        print(f"ERROR: Input file not found: {file_path}")
        print("Please ensure Step 1 has been completed successfully.")
        return False
    return True

def load_combined_data(file_path):
    """Load the combined dataset from Step 1."""
    try:
        print(f"Loading combined dataset from: {file_path}")
        df = pd.read_csv(file_path)
        
        print(f"  - Loaded {len(df)} rows with {len(df.columns)} columns")
        print(f"  - Available columns: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"ERROR loading combined dataset: {str(e)}")
        return None

def extract_key_columns(df):
    """Extract the key columns needed for analysis."""
    # Define the required key columns
    required_columns = ['reappointed', 'name', 'position', 'org', 'year']
    
    print(f"\nExtracting key columns: {required_columns}")
    
    # Check which columns are available
    available_columns = []
    missing_columns = []
    
    for col in required_columns:
        if col in df.columns:
            available_columns.append(col)
        else:
            missing_columns.append(col)
    
    # Report on column availability
    if missing_columns:
        print(f"WARNING: Missing columns: {missing_columns}")
        print("Analysis will proceed with available columns only.")
    
    if not available_columns:
        print("ERROR: No required columns found in the dataset.")
        return None
    
    # Extract available key columns
    key_data = df[available_columns].copy()
    
    print(f"Successfully extracted {len(available_columns)} key columns")
    print(f"Key dataset contains {len(key_data)} rows")
    
    return key_data

def clean_and_validate_key_data(df):
    """Clean and validate the key columns data."""
    print("\nCleaning and validating key data...")
    
    # Store original counts for comparison
    original_rows = len(df)
    
    # Clean name column
    if 'name' in df.columns:
        print("  - Cleaning 'name' column...")
        # Remove leading/trailing whitespace
        df['name'] = df['name'].astype(str).str.strip()
        # Remove rows with empty names
        before_name_clean = len(df)
        df = df[df['name'].notna() & (df['name'] != '') & (df['name'] != 'nan')]
        after_name_clean = len(df)
        if before_name_clean != after_name_clean:
            print(f"    Removed {before_name_clean - after_name_clean} rows with empty names")
    
    # Clean position column
    if 'position' in df.columns:
        print("  - Cleaning 'position' column...")
        df['position'] = df['position'].astype(str).str.strip()
        # Replace 'nan' strings with actual NaN
        df['position'] = df['position'].replace('nan', np.nan)
    
    # Clean org column
    if 'org' in df.columns:
        print("  - Cleaning 'org' column...")
        df['org'] = df['org'].astype(str).str.strip()
        # Replace 'nan' strings with actual NaN
        df['org'] = df['org'].replace('nan', np.nan)
        # Remove rows with empty organizations (critical for our analysis)
        before_org_clean = len(df)
        df = df[df['org'].notna() & (df['org'] != '') & (df['org'] != 'nan')]
        after_org_clean = len(df)
        if before_org_clean != after_org_clean:
            print(f"    Removed {before_org_clean - after_org_clean} rows with empty organizations")
    
    # Validate reappointed column
    if 'reappointed' in df.columns:
        print("  - Validating 'reappointed' column...")
        # Ensure it's boolean
        if df['reappointed'].dtype != 'bool':
            print("    Converting reappointed column to boolean...")
            df['reappointed'] = df['reappointed'].astype(bool)
        
        # Check for any remaining NaN values
        reappointed_na = df['reappointed'].isna().sum()
        if reappointed_na > 0:
            print(f"    WARNING: {reappointed_na} NaN values in reappointed column")
            df['reappointed'] = df['reappointed'].fillna(False)
    
    # Validate year column
    if 'year' in df.columns:
        print("  - Validating 'year' column...")
        # Ensure year is numeric
        try:
            df['year'] = pd.to_numeric(df['year'], errors='coerce')
            year_na = df['year'].isna().sum()
            if year_na > 0:
                print(f"    WARNING: {year_na} invalid year values found")
                # Remove rows with invalid years
                df = df[df['year'].notna()]
        except Exception as e:
            print(f"    ERROR processing year column: {str(e)}")
    
    final_rows = len(df)
    rows_removed = original_rows - final_rows
    
    if rows_removed > 0:
        print(f"\nData cleaning summary:")
        print(f"  - Original rows: {original_rows:,}")
        print(f"  - Final rows: {final_rows:,}")
        print(f"  - Rows removed: {rows_removed:,} ({(rows_removed/original_rows)*100:.1f}%)")
    else:
        print(f"  - No rows removed during cleaning")
    
    return df

def generate_data_summary(df):
    """Generate comprehensive summary of the key data."""
    print("\n" + "=" * 60)
    print("KEY DATA SUMMARY")
    print("=" * 60)
    
    # Basic statistics
    print(f"Total records: {len(df):,}")
    print(f"Total columns: {len(df.columns)}")
    
    # Column-by-column analysis
    for col in df.columns:
        print(f"\n{col.upper()} COLUMN:")
        
        if col == 'reappointed':
            # Boolean analysis
            value_counts = df[col].value_counts()
            total = len(df)
            for value, count in value_counts.items():
                percentage = (count / total) * 100
                print(f"  {value}: {count:,} ({percentage:.1f}%)")
        
        elif col == 'year':
            # Year analysis
            year_range = f"{df[col].min():.0f} - {df[col].max():.0f}"
            print(f"  Range: {year_range}")
            year_counts = df[col].value_counts().sort_index()
            for year, count in year_counts.items():
                print(f"  {year:.0f}: {count:,}")
        
        elif col in ['name', 'position', 'org']:
            # Categorical analysis
            unique_count = df[col].nunique()
            missing_count = df[col].isna().sum()
            missing_pct = (missing_count / len(df)) * 100
            
            print(f"  Unique values: {unique_count:,}")
            print(f"  Missing values: {missing_count:,} ({missing_pct:.1f}%)")
            
            # Show top 5 most frequent values
            if col == 'org':
                print(f"  Top 5 organizations:")
                top_orgs = df[col].value_counts().head(5)
                for org, count in top_orgs.items():
                    print(f"    {org}: {count:,}")
    
    # Cross-tabulation: reappointed by year
    if 'reappointed' in df.columns and 'year' in df.columns:
        print(f"\nREAPPOINTMENT BY YEAR:")
        reappoint_by_year = df.groupby('year')['reappointed'].agg(['count', 'sum', 'mean'])
        reappoint_by_year.columns = ['Total', 'Reappointed', 'Reappointment_Rate']
        reappoint_by_year['Reappointment_Rate'] = reappoint_by_year['Reappointment_Rate'] * 100
        
        for year, row in reappoint_by_year.iterrows():
            print(f"  {year:.0f}: {row['Reappointed']:.0f}/{row['Total']:.0f} ({row['Reappointment_Rate']:.1f}%)")

def extract_key_columns_main():
    """Main function to extract key columns."""
    print("=" * 60)
    print("STEP 2: EXTRACTING KEY COLUMNS")
    print("=" * 60)
    
    # Setup directories
    base_dir, analysis_dir = setup_directories()
    
    # Define input and output files
    input_file = analysis_dir / "step1_combined_appointments.csv"
    output_file = analysis_dir / "step2_key_columns_data.csv"
    
    # Validate input file exists
    if not validate_input_file(input_file):
        print("Cannot proceed without input file from Step 1.")
        return False
    
    # Load combined data
    combined_df = load_combined_data(input_file)
    if combined_df is None:
        print("Failed to load combined data.")
        return False
    
    # Extract key columns
    key_data = extract_key_columns(combined_df)
    if key_data is None:
        print("Failed to extract key columns.")
        return False
    
    # Clean and validate key data
    cleaned_data = clean_and_validate_key_data(key_data)
    
    # Generate data summary
    generate_data_summary(cleaned_data)
    
    # Save the key columns data
    try:
        cleaned_data.to_csv(output_file, index=False)
        print(f"\n" + "=" * 60)
        print("STEP 2 COMPLETED SUCCESSFULLY")
        print("=" * 60)
        print(f"Output file: {output_file}")
        print(f"Key columns extracted: {list(cleaned_data.columns)}")
        print(f"Final record count: {len(cleaned_data):,}")
        
        # File size comparison
        import os
        input_size = os.path.getsize(input_file) / 1024 / 1024  # MB
        output_size = os.path.getsize(output_file) / 1024 / 1024  # MB
        print(f"File size reduction: {input_size:.1f}MB → {output_size:.1f}MB ({((input_size-output_size)/input_size)*100:.1f}% reduction)")
        
        return True
        
    except Exception as e:
        print(f"ERROR saving key columns data: {str(e)}")
        return False

if __name__ == "__main__":
    success = extract_key_columns_main()
    if not success:
        sys.exit(1)
    
    print("\nReady for Step 3: Mark repeated appointees")