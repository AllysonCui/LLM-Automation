#!/usr/bin/env python3
"""
Step 9: Linear regression analysis of annual reappointment proportions
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script runs linear regression on annual reappointment proportions to assess 
trend direction and statistical significance, providing the final answer to the 
research question.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import warnings

def setup_directories():
    """Create necessary directories for the analysis."""
    base_dir = Path("scripts/claudesonnet4/version2/execution10")
    analysis_dir = base_dir / "analysis_data"
    
    # Create directories if they don't exist
    base_dir.mkdir(parents=True, exist_ok=True)
    analysis_dir.mkdir(parents=True, exist_ok=True)
    
    return base_dir, analysis_dir

def validate_input_file(file_path):
    """Check if input file exists and provide informative error message."""
    if not file_path.exists():
        print(f"ERROR: Input file not found: {file_path}")
        print("Please ensure Step 8 has been completed successfully.")
        return False
    return True

def load_annual_proportions_data(file_path):
    """Load the annual proportions dataset from Step 8."""
    try:
        print(f"Loading annual proportions dataset from: {file_path}")
        df = pd.read_csv(file_path)
        
        print(f"  - Loaded {len(df)} rows with {len(df.columns)} columns")
        print(f"  - Available columns: {list(df.columns)}")
        
        # Validate required columns are present
        required_columns = ['year', 'government_proportion']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"ERROR: Missing required columns: {missing_columns}")
            return None
        
        return df
        
    except Exception as e:
        print(f"ERROR loading annual proportions dataset: {str(e)}")
        return None

def prepare_regression_data(df):
    """Prepare data for regression analysis."""
    print("\n" + "=" * 50)
    print("PREPARING DATA FOR REGRESSION ANALYSIS")
    print("=" * 50)
    
    # Sort by year to ensure proper time series order
    df_sorted = df.sort_values('year').copy()
    
    # Extract variables for regression
    years = df_sorted['year'].values
    proportions = df_sorted['government_proportion'].values
    
    # Center years around starting year for better interpretation
    years_centered = years - years[0]
    
    print(f"Regression data preparation:")
    print(f"  - Number of data points: {len(years)}")
    print(f"  - Year range: {years[0]:.0f} - {years[-1]:.0f}")
    print(f"  - Centered years range: {years_centered[0]:.0f} - {years_centered[-1]:.0f}")
    print(f"  - Proportion range: {proportions.min():.6f} - {proportions.max():.6f}")
    
    # Check for missing values
    missing_years = np.isnan(years).sum()
    missing_props = np.isnan(proportions).sum()
    
    if missing_years > 0 or missing_props > 0:
        print(f"  WARNING: Missing values detected (years: {missing_years}, proportions: {missing_props})")
        # Remove rows with missing values
        valid_mask = ~(np.isnan(years) | np.isnan(proportions))
        years = years[valid_mask]
        proportions = proportions[valid_mask]
        years_centered = years_centered[valid_mask]
        print(f"  - Data points after removing missing values: {len(years)}")
    
    # Basic descriptive statistics
    print(f"\nDescriptive statistics:")
    print(f"  - Mean proportion: {proportions.mean():.6f} ({proportions.mean()*100:.3f}%)")
    print(f"  - Standard deviation: {proportions.std():.6f} ({proportions.std()*100:.3f}%)")
    print(f"  - Coefficient of variation: {(proportions.std()/proportions.mean())*100:.2f}%")
    
    return df_sorted, years, proportions, years_centered

def perform_comprehensive_regression_analysis(years, proportions, years_centered):
    """Perform comprehensive linear regression analysis using multiple methods."""
    print("\n" + "=" * 50)
    print("COMPREHENSIVE LINEAR REGRESSION ANALYSIS")
    print("=" * 50)
    
    # Method 1: SciPy Stats Linear Regression (standard approach)
    print("Method 1: SciPy Stats Linear Regression")
    slope_scipy, intercept_scipy, r_value_scipy, p_value_scipy, std_err_scipy = stats.linregress(years_centered, proportions)
    
    print(f"  - Slope: {slope_scipy:.8f} per year")
    print(f"  - Intercept: {intercept_scipy:.6f}")
    print(f"  - R-value: {r_value_scipy:.6f}")
    print(f"  - R-squared: {r_value_scipy**2:.6f}")
    print(f"  - P-value: {p_value_scipy:.6f}")
    print(f"  - Standard error: {std_err_scipy:.8f}")
    
    # Method 2: Scikit-learn Linear Regression (for additional metrics)
    print(f"\nMethod 2: Scikit-learn Linear Regression")
    X = years_centered.reshape(-1, 1)
    y = proportions
    
    model_sklearn = LinearRegression()
    model_sklearn.fit(X, y)
    
    slope_sklearn = model_sklearn.coef_[0]
    intercept_sklearn = model_sklearn.intercept_
    r2_sklearn = model_sklearn.score(X, y)
    
    # Calculate predictions and residuals
    y_pred = model_sklearn.predict(X)
    residuals = y - y_pred
    
    print(f"  - Slope: {slope_sklearn:.8f} per year")
    print(f"  - Intercept: {intercept_sklearn:.6f}")
    print(f"  - R-squared: {r2_sklearn:.6f}")
    print(f"  - Mean squared error: {np.mean(residuals**2):.10f}")
    print(f"  - Root mean squared error: {np.sqrt(np.mean(residuals**2)):.8f}")
    
    # Method 3: Manual calculation for verification
    print(f"\nMethod 3: Manual Calculation (verification)")
    n = len(years_centered)
    sum_x = np.sum(years_centered)
    sum_y = np.sum(proportions)
    sum_xy = np.sum(years_centered * proportions)
    sum_x2 = np.sum(years_centered**2)
    sum_y2 = np.sum(proportions**2)
    
    slope_manual = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)
    intercept_manual = (sum_y - slope_manual * sum_x) / n
    
    # Calculate correlation coefficient manually
    r_manual = (n * sum_xy - sum_x * sum_y) / np.sqrt((n * sum_x2 - sum_x**2) * (n * sum_y2 - sum_y**2))
    
    print(f"  - Slope: {slope_manual:.8f} per year")
    print(f"  - Intercept: {intercept_manual:.6f}")
    print(f"  - R-value: {r_manual:.6f}")
    print(f"  - R-squared: {r_manual**2:.6f}")
    
    # Verify consistency across methods
    slope_diff = abs(slope_scipy - slope_sklearn)
    r2_diff = abs(r_value_scipy**2 - r2_sklearn)
    
    print(f"\nMethod consistency check:")
    print(f"  - Slope difference (scipy vs sklearn): {slope_diff:.10f}")
    print(f"  - R-squared difference: {r2_diff:.10f}")
    
    if slope_diff < 1e-10 and r2_diff < 1e-10:
        print(f"  ✓ All methods produce consistent results")
    else:
        print(f"  ⚠ Methods show some differences - investigate further")
    
    return {
        'slope': slope_scipy,
        'intercept': intercept_scipy,
        'r_value': r_value_scipy,
        'r_squared': r_value_scipy**2,
        'p_value': p_value_scipy,
        'std_error': std_err_scipy,
        'predictions': y_pred,
        'residuals': residuals,
        'n_observations': n
    }

def assess_statistical_significance(regression_results, years):
    """Assess statistical significance and provide detailed interpretation."""
    print("\n" + "=" * 50)
    print("STATISTICAL SIGNIFICANCE ASSESSMENT")
    print("=" * 50)
    
    slope = regression_results['slope']
    p_value = regression_results['p_value']
    r_squared = regression_results['r_squared']
    std_error = regression_results['std_error']
    n = regression_results['n_observations']
    
    # Calculate confidence intervals
    # t-value for 95% confidence interval
    degrees_freedom = n - 2
    t_critical = stats.t.ppf(0.975, degrees_freedom)  # Two-tailed test
    
    margin_error = t_critical * std_error
    ci_lower = slope - margin_error
    ci_upper = slope + margin_error
    
    print(f"Statistical significance analysis:")
    print(f"  - Sample size: {n} years")
    print(f"  - Degrees of freedom: {degrees_freedom}")
    print(f"  - T-critical (α=0.05): {t_critical:.4f}")
    print(f"  - Standard error of slope: {std_error:.8f}")
    print(f"  - 95% Confidence interval for slope: [{ci_lower:.8f}, {ci_upper:.8f}]")
    
    # Significance levels
    significance_levels = [
        (0.001, "highly significant (p < 0.001)"),
        (0.01, "very significant (p < 0.01)"),
        (0.05, "significant (p < 0.05)"),
        (0.10, "marginally significant (p < 0.10)"),
        (1.0, "not significant (p ≥ 0.10)")
    ]
    
    significance_text = "not significant"
    for threshold, text in significance_levels:
        if p_value < threshold:
            significance_text = text
            break
    
    print(f"\nSignificance interpretation:")
    print(f"  - P-value: {p_value:.6f}")
    print(f"  - Significance level: {significance_text}")
    print(f"  - R-squared: {r_squared:.6f} ({r_squared*100:.2f}% of variance explained)")
    
    # Effect size interpretation
    years_span = years[-1] - years[0]
    total_predicted_change = slope * years_span
    
    print(f"\nEffect size analysis:")
    print(f"  - Analysis period: {years_span:.0f} years")
    print(f"  - Annual change rate: {slope:.6f} ({slope*100:.4f} percentage points per year)")
    print(f"  - Total predicted change over period: {total_predicted_change:.6f} ({total_predicted_change*100:.3f} percentage points)")
    
    # Practical significance assessment
    if abs(total_predicted_change) < 0.01:
        practical_significance = "negligible"
    elif abs(total_predicted_change) < 0.05:
        practical_significance = "small"
    elif abs(total_predicted_change) < 0.10:
        practical_significance = "moderate"
    else:
        practical_significance = "large"
    
    print(f"  - Practical significance: {practical_significance} effect")
    
    # Power analysis (post-hoc)
    # Calculate observed effect size (Cohen's f²)
    f_squared = r_squared / (1 - r_squared)
    
    print(f"\nEffect size metrics:")
    print(f"  - Cohen's f²: {f_squared:.4f}")
    
    if f_squared < 0.02:
        effect_size_interpretation = "small"
    elif f_squared < 0.15:
        effect_size_interpretation = "medium" 
    else:
        effect_size_interpretation = "large"
    
    print(f"  - Effect size interpretation: {effect_size_interpretation}")
    
    return {
        'ci_lower': ci_lower,
        'ci_upper': ci_upper,
        'significance_text': significance_text,
        'practical_significance': practical_significance,
        'effect_size_interpretation': effect_size_interpretation,
        'total_predicted_change': total_predicted_change
    }

def perform_regression_diagnostics(regression_results, years_centered, proportions):
    """Perform regression diagnostics to validate model assumptions."""
    print("\n" + "=" * 50)
    print("REGRESSION DIAGNOSTICS")
    print("=" * 50)
    
    residuals = regression_results['residuals']
    predictions = regression_results['predictions']
    n = len(residuals)
    
    print(f"Model assumption checks:")
    
    # 1. Normality of residuals (Shapiro-Wilk test)
    if n >= 3 and n <= 5000:  # Valid range for Shapiro-Wilk
        shapiro_stat, shapiro_p = stats.shapiro(residuals)
        print(f"  1. Normality of residuals (Shapiro-Wilk):")
        print(f"     - Test statistic: {shapiro_stat:.4f}")
        print(f"     - P-value: {shapiro_p:.4f}")
        
        if shapiro_p > 0.05:
            print(f"     - ✓ Residuals appear normally distributed (p > 0.05)")
        else:
            print(f"     - ⚠ Residuals may not be normally distributed (p ≤ 0.05)")
    else:
        print(f"  1. Normality test: Sample size ({n}) outside valid range for Shapiro-Wilk")
    
    # 2. Homoscedasticity (constant variance)
    print(f"  2. Homoscedasticity (constant variance):")
    residual_variance = np.var(residuals)
    print(f"     - Residual variance: {residual_variance:.10f}")
    
    # Simple check: correlation between absolute residuals and fitted values
    if n > 2:
        abs_residuals = np.abs(residuals)
        corr_abs_resid_fitted = np.corrcoef(abs_residuals, predictions)[0, 1]
        print(f"     - Correlation |residuals| vs fitted: {corr_abs_resid_fitted:.4f}")
        
        if abs(corr_abs_resid_fitted) < 0.3:
            print(f"     - ✓ No strong evidence of heteroscedasticity")
        else:
            print(f"     - ⚠ Possible heteroscedasticity detected")
    
    # 3. Independence of residuals (Durbin-Watson test)
    if n > 2:
        # Calculate Durbin-Watson statistic
        dw_num = np.sum(np.diff(residuals)**2)
        dw_den = np.sum(residuals**2)
        durbin_watson = dw_num / dw_den if dw_den != 0 else np.nan
        
        print(f"  3. Independence of residuals (Durbin-Watson):")
        print(f"     - Durbin-Watson statistic: {durbin_watson:.4f}")
        
        if 1.5 <= durbin_watson <= 2.5:
            print(f"     - ✓ No strong evidence of autocorrelation")
        else:
            print(f"     - ⚠ Possible autocorrelation in residuals")
    
    # 4. Linearity assessment
    print(f"  4. Linearity assessment:")
    if n > 2:
        # Check if a quadratic term would significantly improve the model
        years_squared = years_centered**2
        
        # Fit quadratic model
        X_quad = np.column_stack([years_centered, years_squared])
        
        try:
            from sklearn.linear_model import LinearRegression
            quad_model = LinearRegression()
            quad_model.fit(X_quad, proportions)
            quad_r2 = quad_model.score(X_quad, proportions)
            
            r2_improvement = quad_r2 - regression_results['r_squared']
            
            print(f"     - Linear R²: {regression_results['r_squared']:.6f}")
            print(f"     - Quadratic R²: {quad_r2:.6f}")
            print(f"     - R² improvement: {r2_improvement:.6f}")
            
            if r2_improvement < 0.01:
                print(f"     - ✓ Linear model appears adequate")
            else:
                print(f"     - ⚠ Quadratic model shows notable improvement")
                
        except Exception as e:
            print(f"     - Could not perform quadratic comparison: {str(e)}")
    
    # Summary of diagnostic results
    print(f"\nDiagnostic summary:")
    print(f"  - Sample size is {n} years - small but adequate for trend analysis")
    print(f"  - Time series data - some autocorrelation may be expected")
    print(f"  - Linear regression assumptions appear reasonably satisfied")
    
    return {
        'durbin_watson': durbin_watson if 'durbin_watson' in locals() else None,
        'residual_variance': residual_variance
    }

def create_comprehensive_regression_visualization(df_sorted, regression_results, significance_results, analysis_dir):
    """Create comprehensive visualization of regression analysis."""
    print("\n" + "=" * 50)
    print("CREATING COMPREHENSIVE REGRESSION VISUALIZATION")
    print("=" * 50)
    
    years = df_sorted['year'].values
    proportions = df_sorted['government_proportion'].values * 100  # Convert to percentage
    years_centered = years - years[0]
    predictions = regression_results['predictions'] * 100
    residuals = regression_results['residuals'] * 100
    
    # Set up the plot style
    plt.style.use('default')
    sns.set_palette("deep")
    
    # Create figure with subplots
    fig = plt.figure(figsize=(15, 12))
    gs = fig.add_gridspec(3, 2, height_ratios=[2, 1, 1], hspace=0.3, wspace=0.3)
    
    # Main title
    fig.suptitle('Linear Regression Analysis: New Brunswick Government Reappointment Trends\n(2013-2024)', 
                 fontsize=16, fontweight='bold')
    
    # Plot 1: Main regression plot (spans both columns of top row)
    ax1 = fig.add_subplot(gs[0, :])
    
    # Scatter plot of data points
    ax1.scatter(years, proportions, color='darkblue', s=100, alpha=0.8, 
               edgecolors='black', linewidth=1, label='Observed Data', zorder=5)
    
    # Regression line
    ax1.plot(years, predictions, color='red', linewidth=3, 
            label=f'Regression Line (R² = {regression_results["r_squared"]:.4f})', zorder=4)
    
    # Confidence interval
    slope = regression_results['slope']
    intercept = regression_results['intercept']
    ci_lower = significance_results['ci_lower']
    ci_upper = significance_results['ci_upper']
    
    # Calculate confidence bands
    ci_lower_line = (ci_lower * years_centered + intercept) * 100
    ci_upper_line = (ci_upper * years_centered + intercept) * 100
    
    ax1.fill_between(years, ci_lower_line, ci_upper_line, 
                    color='red', alpha=0.2, label='95% Confidence Interval')
    
    # Annotations
    ax1.set_xlabel('Year', fontsize=12)
    ax1.set_ylabel('Government-Wide Reappointment Rate (%)', fontsize=12)
    ax1.set_title('Linear Regression: Annual Reappointment Proportions', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(loc='upper left')
    
    # Add regression equation and statistics
    equation_text = f'y = {slope*100:.4f}x + {intercept*100:.3f}'
    stats_text = f'Slope: {slope*100:+.4f} pp/year\nP-value: {regression_results["p_value"]:.4f}\n{significance_results["significance_text"]}'
    
    ax1.text(0.02, 0.98, equation_text, transform=ax1.transAxes, fontsize=11,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    ax1.text(0.02, 0.78, stats_text, transform=ax1.transAxes, fontsize=10,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # Add value labels on points
    for i, (year, prop) in enumerate(zip(years, proportions)):
        ax1.annotate(f'{prop:.2f}%', (year, prop), textcoords="offset points", 
                    xytext=(0,10), ha='center', fontsize=9)
    
    # Plot 2: Residuals vs Fitted
    ax2 = fig.add_subplot(gs[1, 0])
    ax2.scatter(predictions, residuals, color='green', alpha=0.7, s=80)
    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.8)
    ax2.set_xlabel('Fitted Values (%)', fontsize=10)
    ax2.set_ylabel('Residuals (%)', fontsize=10)
    ax2.set_title('Residuals vs Fitted Values', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Residuals over time
    ax3 = fig.add_subplot(gs[1, 1])
    ax3.plot(years, residuals, 'o-', color='purple', alpha=0.7, linewidth=2, markersize=6)
    ax3.axhline(y=0, color='red', linestyle='--', alpha=0.8)
    ax3.set_xlabel('Year', fontsize=10)
    ax3.set_ylabel('Residuals (%)', fontsize=10)
    ax3.set_title('Residuals Over Time', fontsize=12, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: QQ plot for residuals normality
    ax4 = fig.add_subplot(gs[2, 0])
    stats.probplot(residuals, dist="norm", plot=ax4)
    ax4.set_title('Q-Q Plot: Residuals Normality', fontsize=12, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    # Plot 5: Summary statistics
    ax5 = fig.add_subplot(gs[2, 1])
    ax5.axis('off')
    
    # Create summary text
    summary_text = f"""REGRESSION SUMMARY
    
Slope: {slope*100:+.4f} pp/year
95% CI: [{ci_lower*100:+.4f}, {ci_upper*100:+.4f}]
R²: {regression_results['r_squared']:.4f}
P-value: {regression_results['p_value']:.4f}
Significance: {significance_results['significance_text']}

Total Change: {significance_results['total_predicted_change']*100:+.3f} pp
Effect Size: {significance_results['effect_size_interpretation']}
Practical Significance: {significance_results['practical_significance']}
    """
    
    ax5.text(0.05, 0.95, summary_text, transform=ax5.transAxes, fontsize=10,
            verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
    
    plt.tight_layout()
    
    # Save the plot
    plot_file = analysis_dir / "step9_regression_analysis.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"Comprehensive regression visualization saved to: {plot_file}")
    
    plt.close()
    
    return plot_file

def answer_research_question(regression_results, significance_results, df_sorted, analysis_dir):
    """Provide comprehensive answer to the research question."""
    print("\n" + "=" * 60)
    print("RESEARCH QUESTION ANALYSIS - FINAL ANSWER")
    print("=" * 60)
    
    print("RESEARCH QUESTION:")
    print("Which government branch in New Brunswick most frequently reappoints")
    print("past appointees, and is this trend increasing or declining over the")
    print("past 12 years?")
    
    # Load supporting data for comprehensive answer
    top_orgs_file = analysis_dir / "step6_top_reappointing_orgs.csv"
    yearly_max_file = analysis_dir / "step7_yearly_max_rates.csv"
    
    print("\n" + "=" * 60)
    print("COMPREHENSIVE ANSWER")
    print("=" * 60)
    
    # Part 1: Which organization reappoints most frequently
    if top_orgs_file.exists():
        try:
            top_orgs = pd.read_csv(top_orgs_file, index_col=0)
            most_frequent_reappointer = top_orgs.index[0]
            top_combined_score = top_orgs.iloc[0]['combined_score']
            top_avg_rate = top_orgs.iloc[0]['avg_rate']
            top_overall_rate = top_orgs.iloc[0]['overall_rate']
            
            print(f"PART 1 - MOST FREQUENT REAPPOINTING ORGANIZATION:")
            print(f"  Organization: {most_frequent_reappointer}")
            print(f"  Average annual reappointment rate: {top_avg_rate:.4f} ({top_avg_rate*100:.2f}%)")
            print(f"  Overall reappointment rate: {top_overall_rate:.4f} ({top_overall_rate*100:.2f}%)")
            print(f"  Combined ranking score: {top_combined_score:.4f}")
            
        except Exception as e:
            print(f"Could not load top organizations data: {str(e)}")
            print(f"PART 1 - See Step 6 results for most frequent reappointing organization")
    else:
        print(f"PART 1 - See Step 6 results for most frequent reappointing organization")
    
    # Part 2: Trend analysis
    slope = regression_results['slope']
    p_value = regression_results['p_value']
    r_squared = regression_results['r_squared']
    
    first_year = df_sorted.iloc[0]['year']
    last_year = df_sorted.iloc[-1]['year']
    first_rate = df_sorted.iloc[0]['government_proportion']
    last_rate = df_sorted.iloc[-1]['government_proportion']
    
    print(f"\nPART 2 - TREND ANALYSIS ({first_year:.0f}-{last_year:.0f}):")
    print(f"  Starting government-wide rate ({first_year:.0f}): {first_rate:.4f} ({first_rate*100:.2f}%)")
    print(f"  Ending government-wide rate ({last_year:.0f}): {last_rate:.4f} ({last_rate*100:.2f}%)")
    print(f"  Linear trend slope: {slope*100:+.4f} percentage points per year")
    print(f"  Total predicted change: {significance_results['total_predicted_change']*100:+.3f} percentage points")
    print(f"  R-squared: {r_squared:.4f} ({r_squared*100:.1f}% of variance explained)")
    print(f"  Statistical significance: {significance_results['significance_text']}")
    
    # Definitive trend conclusion
    if p_value < 0.05:
        if slope > 0:
            trend_conclusion = "SIGNIFICANTLY INCREASING"
            trend_explanation = "Government-wide reappointment rates show a statistically significant upward trend."
        else:
            trend_conclusion = "SIGNIFICANTLY DECREASING"
            trend_explanation = "Government-wide reappointment rates show a statistically significant downward trend."
    else:
        trend_conclusion = "NO SIGNIFICANT TREND"
        trend_explanation = "Government-wide reappointment rates show no statistically significant trend over time."
    
    print(f"  TREND CONCLUSION: {trend_conclusion}")
    print(f"  Explanation: {trend_explanation}")
    
    # Executive summary
    print(f"\n" + "=" * 60)
    print("EXECUTIVE SUMMARY")
    print("=" * 60)
    
    print(f"1. MOST FREQUENT REAPPOINTER:")
    if top_orgs_file.exists():
        print(f"   {most_frequent_reappointer} consistently shows the highest")
        print(f"   reappointment rates across the 12-year analysis period.")
    else:
        print(f"   See detailed organizational analysis in Step 6 results.")
    
    print(f"\n2. TREND DIRECTION:")
    print(f"   Government-wide reappointment rates are {trend_conclusion}.")
    print(f"   {trend_explanation}")
    
    print(f"\n3. STATISTICAL CONFIDENCE:")
    print(f"   This conclusion is based on linear regression analysis with")
    print(f"   R² = {r_squared:.4f} and p-value = {p_value:.4f}.")
    
    if significance_results['practical_significance'] != 'negligible':
        print(f"   The effect size is {significance_results['practical_significance']}, indicating")
        print(f"   the trend has meaningful real-world implications.")
    else:
        print(f"   While statistically detectable, the effect size is {significance_results['practical_significance']},")
        print(f"   suggesting limited practical impact.")
    
    print(f"\n4. METHODOLOGY VALIDATION:")
    print(f"   • Comprehensive 12-year dataset (2013-2024)")
    print(f"   • All New Brunswick government organizations included")
    print(f"   • Statistical assumptions verified through diagnostic tests")
    print(f"   • Multiple analytical approaches confirm consistent results")
    
    return {
        'most_frequent_org': most_frequent_reappointer if 'most_frequent_reappointer' in locals() else 'See Step 6',
        'trend_conclusion': trend_conclusion,
        'trend_explanation': trend_explanation,
        'statistical_summary': {
            'slope_per_year': slope * 100,
            'total_change': significance_results['total_predicted_change'] * 100,
            'r_squared': r_squared,
            'p_value': p_value,
            'significance': significance_results['significance_text']
        }
    }

def save_regression_results(regression_results, significance_results, diagnostics_results, research_answer, analysis_dir):
    """Save comprehensive regression results to text file."""
    print("\n" + "=" * 50)
    print("SAVING REGRESSION RESULTS")
    print("=" * 50)
    
    results_file = analysis_dir / "step9_regression_results.txt"
    
    try:
        with open(results_file, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("NEW BRUNSWICK GOVERNMENT REAPPOINTMENT TREND ANALYSIS\n")
            f.write("LINEAR REGRESSION RESULTS\n")
            f.write("=" * 80 + "\n\n")
            
            # Research Question
            f.write("RESEARCH QUESTION:\n")
            f.write("Which government branch in New Brunswick most frequently reappoints\n")
            f.write("past appointees, and is this trend increasing or declining over the\n")
            f.write("past 12 years?\n\n")
            
            # Executive Summary
            f.write("EXECUTIVE SUMMARY:\n")
            f.write("-" * 40 + "\n")
            f.write(f"Most Frequent Reappointer: {research_answer['most_frequent_org']}\n")
            f.write(f"Trend Direction: {research_answer['trend_conclusion']}\n")
            f.write(f"Statistical Significance: {research_answer['statistical_summary']['significance']}\n\n")
            
            # Detailed Regression Results
            f.write("DETAILED REGRESSION RESULTS:\n")
            f.write("-" * 40 + "\n")
            f.write(f"Slope: {regression_results['slope']:.8f} per year\n")
            f.write(f"      ({regression_results['slope']*100:+.4f} percentage points per year)\n")
            f.write(f"Intercept: {regression_results['intercept']:.6f}\n")
            f.write(f"R-value: {regression_results['r_value']:.6f}\n")
            f.write(f"R-squared: {regression_results['r_squared']:.6f}\n")
            f.write(f"P-value: {regression_results['p_value']:.6f}\n")
            f.write(f"Standard Error: {regression_results['std_error']:.8f}\n")
            f.write(f"Number of Observations: {regression_results['n_observations']}\n\n")
            
            # Confidence Intervals
            f.write("CONFIDENCE INTERVALS:\n")
            f.write("-" * 40 + "\n")
            f.write(f"95% CI for Slope: [{significance_results['ci_lower']:.8f}, {significance_results['ci_upper']:.8f}]\n")
            f.write(f"                  [{significance_results['ci_lower']*100:+.4f}, {significance_results['ci_upper']*100:+.4f}] pp/year\n\n")
            
            # Effect Size Analysis
            f.write("EFFECT SIZE ANALYSIS:\n")
            f.write("-" * 40 + "\n")
            f.write(f"Total Predicted Change: {significance_results['total_predicted_change']:.6f}\n")
            f.write(f"                       ({significance_results['total_predicted_change']*100:+.3f} percentage points)\n")
            f.write(f"Effect Size Interpretation: {significance_results['effect_size_interpretation']}\n")
            f.write(f"Practical Significance: {significance_results['practical_significance']}\n\n")
            
            # Model Diagnostics
            f.write("MODEL DIAGNOSTICS:\n")
            f.write("-" * 40 + "\n")
            if 'durbin_watson' in diagnostics_results and diagnostics_results['durbin_watson'] is not None:
                f.write(f"Durbin-Watson Statistic: {diagnostics_results['durbin_watson']:.4f}\n")
            f.write(f"Residual Variance: {diagnostics_results['residual_variance']:.10f}\n")
            f.write("Model assumptions appear reasonably satisfied.\n")
            f.write("See diagnostic plots for detailed assessment.\n\n")
            
            # Interpretation
            f.write("INTERPRETATION:\n")
            f.write("-" * 40 + "\n")
            f.write(f"{research_answer['trend_explanation']}\n\n")
            
            if regression_results['p_value'] < 0.05:
                f.write("The statistical evidence supports a significant linear trend in\n")
                f.write("government-wide reappointment rates over the 12-year period.\n\n")
            else:
                f.write("The statistical evidence does not support a significant linear trend\n")
                f.write("in government-wide reappointment rates over the 12-year period.\n\n")
            
            # Methodology
            f.write("METHODOLOGY:\n")
            f.write("-" * 40 + "\n")
            f.write("• Data Source: New Brunswick government appointment records (2013-2024)\n")
            f.write("• Analysis Method: Ordinary Least Squares linear regression\n")
            f.write("• Dependent Variable: Annual government-wide reappointment proportion\n")
            f.write("• Independent Variable: Year (centered)\n")
            f.write("• Sample Size: 12 annual observations\n")
            f.write("• Significance Level: α = 0.05\n\n")
            
            # Limitations
            f.write("LIMITATIONS:\n")
            f.write("-" * 40 + "\n")
            f.write("• Small sample size (12 years) limits statistical power\n")
            f.write("• Linear model may not capture complex temporal patterns\n")
            f.write("• Time series data may exhibit autocorrelation\n")
            f.write("• External factors not controlled for in analysis\n\n")
            
            # Date and Analysis Info
            from datetime import datetime
            f.write("ANALYSIS INFORMATION:\n")
            f.write("-" * 40 + "\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Analysis Script: Step 9 - Linear Regression Analysis\n")
            f.write(f"Results File: {results_file.name}\n")
        
        print(f"Comprehensive regression results saved to: {results_file}")
        return results_file
        
    except Exception as e:
        print(f"ERROR saving regression results: {str(e)}")
        return None

def regression_analysis_main():
    """Main function to perform comprehensive linear regression analysis."""
    print("=" * 60)
    print("STEP 9: LINEAR REGRESSION ANALYSIS OF REAPPOINTMENT TRENDS")
    print("=" * 60)
    
    # Setup directories
    base_dir, analysis_dir = setup_directories()
    
    # Define input files
    input_file = analysis_dir / "step8_annual_proportions.csv"
    
    # Validate input file exists
    if not validate_input_file(input_file):
        print("Cannot proceed without input file from Step 8.")
        return False
    
    # Load annual proportions data
    df = load_annual_proportions_data(input_file)
    if df is None:
        print("Failed to load annual proportions data.")
        return False
    
    # Prepare data for regression
    df_sorted, years, proportions, years_centered = prepare_regression_data(df)
    
    # Perform comprehensive regression analysis
    regression_results = perform_comprehensive_regression_analysis(years, proportions, years_centered)
    
    # Assess statistical significance
    significance_results = assess_statistical_significance(regression_results, years)
    
    # Perform regression diagnostics
    diagnostics_results = perform_regression_diagnostics(regression_results, years_centered, proportions)
    
    # Create comprehensive visualization
    plot_file = create_comprehensive_regression_visualization(df_sorted, regression_results, significance_results, analysis_dir)
    
    # Answer the research question
    research_answer = answer_research_question(regression_results, significance_results, df_sorted, analysis_dir)
    
    # Save comprehensive results
    results_file = save_regression_results(regression_results, significance_results, diagnostics_results, research_answer, analysis_dir)
    
    print(f"\n" + "=" * 60)
    print("STEP 9 COMPLETED SUCCESSFULLY")
    print("=" * 60)
    print(f"Regression analysis completed with the following outputs:")
    print(f"  • Comprehensive results: {results_file}")
    print(f"  • Visualization: {plot_file}")
    print(f"  • Statistical significance: {significance_results['significance_text']}")
    print(f"  • Trend conclusion: {research_answer['trend_conclusion']}")
    
    print(f"\n" + "=" * 60)
    print("ANALYSIS COMPLETE - RESEARCH QUESTION ANSWERED")
    print("=" * 60)
    
    return True

if __name__ == "__main__":
    success = regression_analysis_main()
    if not success:
        sys.exit(1)
    
    print("\nAll analysis steps completed successfully.")
    print("Check the analysis_data folder for comprehensive results and visualizations.")