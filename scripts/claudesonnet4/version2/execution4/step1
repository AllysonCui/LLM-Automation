#!/usr/bin/env python3
"""
Step 1: Combine Raw Datasets
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script combines 12 CSV files (2013-2024) containing New Brunswick government 
appointment data into a single consolidated dataset.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

def create_output_directory(output_path):
    """Create output directory if it doesn't exist."""
    try:
        output_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ“ Output directory created/verified: {output_path}")
        return True
    except Exception as e:
        print(f"âœ— Error creating output directory: {e}")
        return False

def validate_file_exists(file_path):
    """Check if a file exists and is readable."""
    if not file_path.exists():
        print(f"âœ— File not found: {file_path}")
        return False
    elif not file_path.is_file():
        print(f"âœ— Path is not a file: {file_path}")
        return False
    else:
        print(f"âœ“ File found: {file_path}")
        return True

def load_csv_with_validation(file_path, year):
    """Load CSV file with error handling and basic validation."""
    try:
        # Read CSV file
        df = pd.read_csv(file_path)
        
        # Add year column to track source
        df['source_year'] = year
        
        # Basic validation
        if df.empty:
            print(f"âš  Warning: {file_path.name} is empty")
            return df
        
        print(f"âœ“ Loaded {file_path.name}: {len(df)} rows, {len(df.columns)-1} columns (+ source_year)")
        
        # Display column names for verification
        print(f"  Columns: {list(df.columns[:-1])}")  # Exclude source_year from display
        
        return df
        
    except FileNotFoundError:
        print(f"âœ— Error: File not found - {file_path}")
        return None
    except pd.errors.EmptyDataError:
        print(f"âœ— Error: Empty file - {file_path}")
        return None
    except pd.errors.ParserError as e:
        print(f"âœ— Error parsing CSV {file_path}: {e}")
        return None
    except Exception as e:
        print(f"âœ— Unexpected error loading {file_path}: {e}")
        return None

def combine_datasets():
    """Main function to combine all appointment datasets."""
    print("="*60)
    print("STEP 1: COMBINING RAW DATASETS")
    print("="*60)
    
    # Define paths
    raw_data_path = Path("raw_data")
    output_path = Path("scripts/claudesonnet4/version2/execution4/analysis_data")
    output_file = output_path / "step1_combined_appointments.csv"
    
    # Create output directory
    if not create_output_directory(output_path):
        return False
    
    # Check if raw data directory exists
    if not raw_data_path.exists():
        print(f"âœ— Raw data directory not found: {raw_data_path}")
        print("Please ensure the 'raw_data' directory exists with appointment CSV files.")
        return False
    
    print(f"âœ“ Raw data directory found: {raw_data_path}")
    print()
    
    # Initialize list to store dataframes
    all_dataframes = []
    years_range = range(2013, 2025)  # 2013 to 2024 inclusive
    
    print("Loading individual CSV files:")
    print("-" * 40)
    
    # Load each year's data
    for year in years_range:
        file_path = raw_data_path / f"appointments_{year}.csv"
        
        # Validate file exists
        if not validate_file_exists(file_path):
            print(f"âš  Warning: Missing file for year {year}, continuing with available files...")
            continue
        
        # Load and validate CSV
        df = load_csv_with_validation(file_path, year)
        
        if df is not None and not df.empty:
            all_dataframes.append(df)
            print(f"  âœ“ Successfully added {year} data")
        else:
            print(f"  âœ— Failed to load {year} data")
        print()
    
    # Check if we have any data to combine
    if not all_dataframes:
        print("âœ— No valid data files found. Cannot proceed with combination.")
        return False
    
    print("="*40)
    print("COMBINING DATASETS")
    print("="*40)
    
    try:
        # Combine all dataframes
        print(f"Combining {len(all_dataframes)} datasets...")
        combined_df = pd.concat(all_dataframes, ignore_index=True, sort=False)
        
        # Validation of combined dataset
        print(f"âœ“ Successfully combined datasets")
        print(f"  Total rows: {len(combined_df):,}")
        print(f"  Total columns: {len(combined_df.columns)}")
        print(f"  Years represented: {sorted(combined_df['source_year'].unique())}")
        
        # Check for missing values summary
        missing_summary = combined_df.isnull().sum()
        if missing_summary.sum() > 0:
            print(f"\nğŸ“Š Missing values summary:")
            for col, missing_count in missing_summary.items():
                if missing_count > 0:
                    percentage = (missing_count / len(combined_df)) * 100
                    print(f"  {col}: {missing_count:,} ({percentage:.1f}%)")
        else:
            print("âœ“ No missing values detected")
        
        # Display sample of combined data
        print(f"\nğŸ“‹ Sample of combined data (first 3 rows):")
        print(combined_df.head(3).to_string())
        
        # Save combined dataset
        print(f"\nğŸ’¾ Saving combined dataset to: {output_file}")
        combined_df.to_csv(output_file, index=False)
        print(f"âœ“ Successfully saved: {len(combined_df):,} rows")
        
        # Final validation - verify saved file
        try:
            verification_df = pd.read_csv(output_file)
            if len(verification_df) == len(combined_df):
                print("âœ“ File save verification successful")
            else:
                print("âš  Warning: Saved file row count doesn't match combined data")
        except Exception as e:
            print(f"âš  Warning: Could not verify saved file: {e}")
        
        print("\n" + "="*60)
        print("STEP 1 COMPLETED SUCCESSFULLY")
        print("="*60)
        print(f"Output: {output_file}")
        print(f"Combined {len(all_dataframes)} files into {len(combined_df):,} total appointments")
        print("Ready for Step 2: Key columns extraction")
        
        return True
        
    except Exception as e:
        print(f"âœ— Error combining datasets: {e}")
        return False

if __name__ == "__main__":
    success = combine_datasets()
    if not success:
        print("\nâŒ Step 1 failed. Please check the errors above and retry.")
        sys.exit(1)
    else:
        print("\nâœ… Step 1 completed successfully!")