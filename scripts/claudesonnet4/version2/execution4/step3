#!/usr/bin/env python3
"""
Step 3: Mark Repeats
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script marks "reappointed" as True for repeated "name"-"position"-"org" 
combinations, except for the first appearance (which remains False).
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

def validate_input_file(input_file):
    """Validate that the input file exists and has required columns."""
    if not input_file.exists():
        print(f"✗ Input file not found: {input_file}")
        print("Please run Step 2 first to create the key columns dataset.")
        return False
    
    try:
        # Read and validate required columns
        df = pd.read_csv(input_file)
        required_columns = ['name', 'position', 'org', 'year', 'reappointed']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"✗ Missing required columns: {missing_columns}")
            print(f"Available columns: {list(df.columns)}")
            return False
        
        print(f"✓ Input file validated: {input_file}")
        print(f"  Records: {len(df):,}")
        print(f"  Required columns present: {required_columns}")
        return True
        
    except Exception as e:
        print(f"✗ Error reading input file: {e}")
        return False

def clean_combination_fields(df):
    """Clean and standardize the name, position, and org fields for combination matching."""
    print("🧹 Cleaning combination fields for accurate matching:")
    
    df_cleaned = df.copy()
    
    # Clean name field
    if 'name' in df_cleaned.columns:
        original_unique = df_cleaned['name'].nunique()
        df_cleaned['name_clean'] = (df_cleaned['name']
                                   .astype(str)
                                   .str.strip()
                                   .str.title()  # Consistent capitalization
                                   .replace('', np.nan))
        cleaned_unique = df_cleaned['name_clean'].nunique()
        print(f"  Name field: {original_unique} → {cleaned_unique} unique values")
    
    # Clean position field
    if 'position' in df_cleaned.columns:
        original_unique = df_cleaned['position'].nunique()
        df_cleaned['position_clean'] = (df_cleaned['position']
                                       .astype(str)
                                       .str.strip()
                                       .str.title()
                                       .replace('', np.nan))
        cleaned_unique = df_cleaned['position_clean'].nunique()
        print(f"  Position field: {original_unique} → {cleaned_unique} unique values")
    
    # Clean organization field
    if 'org' in df_cleaned.columns:
        original_unique = df_cleaned['org'].nunique()
        df_cleaned['org_clean'] = (df_cleaned['org']
                                  .astype(str)
                                  .str.strip()
                                  .str.title()
                                  .replace('', np.nan))
        cleaned_unique = df_cleaned['org_clean'].nunique()
        print(f"  Organization field: {original_unique} → {cleaned_unique} unique values")
    
    return df_cleaned

def identify_repeat_appointments(df):
    """Identify and mark repeat appointments based on name-position-org combinations."""
    print("🔍 Identifying repeat appointments:")
    
    # Create combination key for tracking repeats
    df['combination_key'] = (df['name_clean'].astype(str) + '|' + 
                           df['position_clean'].astype(str) + '|' + 
                           df['org_clean'].astype(str))
    
    # Remove rows where any key field is missing
    valid_combinations_mask = (df['name_clean'].notna() & 
                              df['position_clean'].notna() & 
                              df['org_clean'].notna())
    
    invalid_count = (~valid_combinations_mask).sum()
    if invalid_count > 0:
        print(f"  ⚠ Warning: {invalid_count:,} records have missing key fields and will be excluded from repeat analysis")
    
    df_valid = df[valid_combinations_mask].copy()
    
    # Sort by year to ensure chronological order for first appearance identification
    df_valid = df_valid.sort_values(['combination_key', 'year']).reset_index(drop=True)
    
    # Count occurrences of each combination
    combination_counts = df_valid['combination_key'].value_counts()
    
    print(f"  Total unique name-position-org combinations: {len(combination_counts):,}")
    print(f"  Combinations appearing once: {(combination_counts == 1).sum():,}")
    print(f"  Combinations appearing multiple times: {(combination_counts > 1).sum():,}")
    
    # Identify repeats by marking duplicates (keeping first occurrence as False)
    df_valid['is_repeat'] = df_valid.duplicated(subset=['combination_key'], keep='first')
    
    # Update the reappointed column based on repeat identification
    # Original reappointed value OR identified as repeat
    df_valid['reappointed_updated'] = df_valid['reappointed'] | df_valid['is_repeat']
    
    # Merge back with invalid combinations (keeping their original reappointed status)
    df_invalid = df[~valid_combinations_mask].copy()
    df_invalid['is_repeat'] = False
    df_invalid['reappointed_updated'] = df_invalid['reappointed']
    
    # Combine valid and invalid records
    df_final = pd.concat([df_valid, df_invalid], ignore_index=True)
    
    return df_final, combination_counts

def analyze_repeat_patterns(df, combination_counts):
    """Analyze patterns in repeat appointments."""
    print("\n📊 Analyzing repeat appointment patterns:")
    
    # Basic statistics
    total_appointments = len(df)
    reappointed_count = df['reappointed_updated'].sum()
    reappointment_rate = (reappointed_count / total_appointments) * 100
    
    print(f"  Total appointments: {total_appointments:,}")
    print(f"  Reappointed appointments: {reappointed_count:,} ({reappointment_rate:.1f}%)")
    print(f"  First-time appointments: {total_appointments - reappointed_count:,} ({100 - reappointment_rate:.1f}%)")
    
    # Changes made by the repeat identification
    original_reappointed = df['reappointed'].sum()
    newly_identified = reappointed_count - original_reappointed
    
    print(f"\n🔄 Changes made by repeat identification:")
    print(f"  Originally marked as reappointed: {original_reappointed:,}")
    print(f"  Newly identified as reappointed: {newly_identified:,}")
    print(f"  Total now marked as reappointed: {reappointed_count:,}")
    
    # Most frequently reappointed combinations
    frequent_repeats = combination_counts[combination_counts > 2].sort_values(ascending=False)
    if len(frequent_repeats) > 0:
        print(f"\n🔥 Most frequently reappointed combinations (>2 times):")
        for i, (combo_key, count) in enumerate(frequent_repeats.head(10).items()):
            # Parse the combination key back to readable format
            name, position, org = combo_key.split('|')
            print(f"    {i+1:2d}. {name} as {position} at {org}: {count} times")
    
    # Year-over-year analysis
    if 'year' in df.columns:
        print(f"\n📈 Reappointment trends by year:")
        yearly_stats = df.groupby('year').agg({
            'reappointed_updated': ['count', 'sum']
        }).round(1)
        yearly_stats.columns = ['Total_Appointments', 'Reappointments']
        yearly_stats['Reappointment_Rate'] = (yearly_stats['Reappointments'] / yearly_stats['Total_Appointments'] * 100).round(1)
        
        for year in sorted(df['year'].unique()):
            stats = yearly_stats.loc[year]
            print(f"    {year}: {int(stats['Reappointments']):,}/{int(stats['Total_Appointments']):,} ({stats['Reappointment_Rate']:.1f}%)")
    
    # Organization analysis
    if 'org_clean' in df.columns:
        print(f"\n🏛️ Top 10 organizations by reappointment count:")
        org_stats = df[df['reappointed_updated'] == True]['org_clean'].value_counts().head(10)
        for org, count in org_stats.items():
            total_org_appointments = df[df['org_clean'] == org].shape[0]
            rate = (count / total_org_appointments * 100) if total_org_appointments > 0 else 0
            print(f"    {org}: {count:,} reappointments ({rate:.1f}% of {total_org_appointments:,} total)")

def mark_repeats():
    """Main function to mark repeat appointments."""
    print("="*60)
    print("STEP 3: MARKING REPEAT APPOINTMENTS")
    print("="*60)
    
    # Define paths
    input_path = Path("scripts/claudesonnet4/version2/execution4/analysis_data")
    input_file = input_path / "step2_key_columns_data.csv"
    output_file = input_path / "step3_repeats_marked.csv"
    
    # Validate input file
    if not validate_input_file(input_file):
        return False
    
    try:
        # Load the key columns dataset
        print(f"\n📂 Loading key columns dataset...")
        df = pd.read_csv(input_file)
        print(f"✓ Loaded dataset: {len(df):,} rows, {len(df.columns)} columns")
        
        # Display original reappointment distribution
        original_reapp_counts = df['reappointed'].value_counts(dropna=False)
        print(f"\n📋 Original reappointment distribution:")
        for status, count in original_reapp_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  {repr(status)}: {count:,} ({percentage:.1f}%)")
        
        # Clean combination fields
        print(f"\n🔧 Preparing data for repeat identification:")
        df_cleaned = clean_combination_fields(df)
        
        # Identify repeat appointments
        print(f"\n🎯 Identifying repeat appointments:")
        df_with_repeats, combination_counts = identify_repeat_appointments(df_cleaned)
        
        # Analyze repeat patterns
        analyze_repeat_patterns(df_with_repeats, combination_counts)
        
        # Prepare final dataset
        print(f"\n📦 Preparing final dataset:")
        
        # Keep original columns plus updated reappointed column
        final_columns = ['name', 'position', 'org', 'year', 'reappointed_updated']
        df_final = df_with_repeats[final_columns].copy()
        df_final = df_final.rename(columns={'reappointed_updated': 'reappointed'})
        
        print(f"  Final dataset: {len(df_final):,} rows, {len(df_final.columns)} columns")
        print(f"  Columns: {list(df_final.columns)}")
        
        # Display sample of final data
        print(f"\n📋 Sample of processed data (first 5 rows):")
        print(df_final.head().to_string())
        
        # Save the dataset with marked repeats
        print(f"\n💾 Saving dataset with marked repeats to: {output_file}")
        df_final.to_csv(output_file, index=False)
        print(f"✓ Successfully saved: {len(df_final):,} rows")
        
        # Final validation
        try:
            verification_df = pd.read_csv(output_file)
            if len(verification_df) == len(df_final) and len(verification_df.columns) == len(df_final.columns):
                print("✓ File save verification successful")
                
                # Quick verification of reappointment counts
                saved_reapp_count = verification_df['reappointed'].sum()
                original_reapp_count = df_final['reappointed'].sum()
                if saved_reapp_count == original_reapp_count:
                    print("✓ Reappointment count verification successful")
                else:
                    print("⚠ Warning: Saved file reappointment count doesn't match")
            else:
                print("⚠ Warning: Saved file dimensions don't match processed data")
        except Exception as e:
            print(f"⚠ Warning: Could not verify saved file: {e}")
        
        print("\n" + "="*60)
        print("STEP 3 COMPLETED SUCCESSFULLY")
        print("="*60)
        print(f"Output: {output_file}")
        print(f"Processed {len(df_final):,} appointments with repeat identification")
        print("Ready for Step 4: Appointment counts analysis")
        
        return True
        
    except Exception as e:
        print(f"✗ Error marking repeats: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = mark_repeats()
    if not success:
        print("\n❌ Step 3 failed. Please check the errors above and retry.")
        sys.exit(1)
    else:
        print("\n✅ Step 3 completed successfully!")