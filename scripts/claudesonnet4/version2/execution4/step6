#!/usr/bin/env python3
"""
Step 6: Calculate Reappointment Rates
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script calculates the reappointment rate as reappointments divided by total 
appointments for each org-year pair, combining data from Steps 4 and 5.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

def validate_input_files(step4_file, step5_file):
    """Validate that both Step 4 and Step 5 input files exist and have required columns."""
    print("🔍 Validating input files:")
    
    # Check Step 4 file (total appointments)
    if not step4_file.exists():
        print(f"✗ Step 4 file not found: {step4_file}")
        print("Please run Step 4 first to create appointment counts.")
        return False
    
    # Check Step 5 file (reappointments)
    if not step5_file.exists():
        print(f"✗ Step 5 file not found: {step5_file}")
        print("Please run Step 5 first to create reappointment counts.")
        return False
    
    try:
        # Validate Step 4 file structure
        step4_df = pd.read_csv(step4_file)
        step4_required = ['org_clean', 'year', 'appointment_count']
        step4_missing = [col for col in step4_required if col not in step4_df.columns]
        
        if step4_missing:
            print(f"✗ Step 4 file missing columns: {step4_missing}")
            print(f"Available columns: {list(step4_df.columns)}")
            return False
        
        print(f"✓ Step 4 file validated: {len(step4_df):,} org-year combinations")
        
        # Validate Step 5 file structure
        step5_df = pd.read_csv(step5_file)
        step5_required = ['org_clean', 'year', 'reappointment_count']
        step5_missing = [col for col in step5_required if col not in step5_df.columns]
        
        if step5_missing:
            print(f"✗ Step 5 file missing columns: {step5_missing}")
            print(f"Available columns: {list(step5_df.columns)}")
            return False
        
        print(f"✓ Step 5 file validated: {len(step5_df):,} org-year combinations with reappointments")
        
        return True
        
    except Exception as e:
        print(f"✗ Error validating input files: {e}")
        return False

def load_and_merge_data(step4_file, step5_file):
    """Load and merge data from Steps 4 and 5."""
    print("\n📂 Loading and merging data:")
    
    try:
        # Load total appointments (Step 4)
        total_appointments = pd.read_csv(step4_file)
        print(f"✓ Loaded total appointments: {len(total_appointments):,} org-year combinations")
        
        # Load reappointments (Step 5)
        reappointments = pd.read_csv(step5_file)
        print(f"✓ Loaded reappointments: {len(reappointments):,} org-year combinations")
        
        # Merge the datasets - left join to keep all org-year combinations from Step 4
        merged_data = pd.merge(
            total_appointments[['org_clean', 'year', 'appointment_count']], 
            reappointments[['org_clean', 'year', 'reappointment_count']], 
            on=['org_clean', 'year'], 
            how='left'
        )
        
        # Fill missing reappointment counts with 0 (no reappointments for that org-year)
        merged_data['reappointment_count'] = merged_data['reappointment_count'].fillna(0)
        
        print(f"✓ Merged dataset: {len(merged_data):,} org-year combinations")
        
        # Validate merge results
        print(f"  Data validation:")
        print(f"    Combinations with appointments: {len(merged_data):,}")
        print(f"    Combinations with reappointments: {(merged_data['reappointment_count'] > 0).sum():,}")
        print(f"    Combinations with zero reappointments: {(merged_data['reappointment_count'] == 0).sum():,}")
        
        # Check for any data quality issues
        negative_appointments = (merged_data['appointment_count'] < 0).sum()
        negative_reappointments = (merged_data['reappointment_count'] < 0).sum()
        reapp_exceeds_total = (merged_data['reappointment_count'] > merged_data['appointment_count']).sum()
        
        if negative_appointments > 0 or negative_reappointments > 0 or reapp_exceeds_total > 0:
            print(f"  ⚠ Data quality warnings:")
            if negative_appointments > 0:
                print(f"    Negative appointment counts: {negative_appointments}")
            if negative_reappointments > 0:
                print(f"    Negative reappointment counts: {negative_reappointments}")
            if reapp_exceeds_total > 0:
                print(f"    Reappointments exceed total appointments: {reapp_exceeds_total}")
                print("    This may indicate data quality issues or duplicate counting")
        else:
            print(f"  ✓ No data quality issues detected")
        
        return merged_data
        
    except Exception as e:
        print(f"✗ Error loading and merging data: {e}")
        return None

def calculate_reappointment_rates(merged_data):
    """Calculate reappointment rates for each org-year combination."""
    print("\n📊 Calculating reappointment rates:")
    
    rates_data = merged_data.copy()
    
    # Calculate reappointment rate as percentage
    rates_data['reappointment_rate'] = (
        rates_data['reappointment_count'] / rates_data['appointment_count'] * 100
    ).round(2)
    
    # Handle division by zero (should not occur if data is correct, but safety check)
    zero_appointments = rates_data['appointment_count'] == 0
    if zero_appointments.any():
        zero_count = zero_appointments.sum()
        print(f"  ⚠ Warning: {zero_count} org-year combinations have zero total appointments")
        rates_data.loc[zero_appointments, 'reappointment_rate'] = 0
    
    # Basic statistics
    total_combinations = len(rates_data)
    combinations_with_reapps = (rates_data['reappointment_count'] > 0).sum()
    avg_reapp_rate = rates_data['reappointment_rate'].mean()
    median_reapp_rate = rates_data['reappointment_rate'].median()
    
    print(f"  Rate calculation summary:")
    print(f"    Total org-year combinations: {total_combinations:,}")
    print(f"    Combinations with reappointments: {combinations_with_reapps:,} ({combinations_with_reapps/total_combinations*100:.1f}%)")
    print(f"    Average reappointment rate: {avg_reapp_rate:.1f}%")
    print(f"    Median reappointment rate: {median_reapp_rate:.1f}%")
    
    # Distribution of reappointment rates
    print(f"\n  Reappointment rate distribution:")
    rate_bins = [0, 10, 25, 50, 75, 90, 100]
    for i in range(len(rate_bins)-1):
        lower, upper = rate_bins[i], rate_bins[i+1]
        count = ((rates_data['reappointment_rate'] >= lower) & 
                (rates_data['reappointment_rate'] < upper) if i < len(rate_bins)-2 
                else (rates_data['reappointment_rate'] >= lower) & 
                     (rates_data['reappointment_rate'] <= upper)).sum()
        percentage = count / total_combinations * 100
        print(f"    {lower:2.0f}%-{upper:2.0f}%: {count:,} combinations ({percentage:.1f}%)")
    
    return rates_data

def analyze_top_performers(rates_data):
    """Analyze organizations with highest reappointment rates."""
    print("\n🏆 Analyzing top performing organizations:")
    
    # Filter for organizations with substantial appointment activity (min 10 total appointments)
    org_summary = rates_data.groupby('org_clean').agg({
        'appointment_count': 'sum',
        'reappointment_count': 'sum',
        'reappointment_rate': 'mean'  # Average rate across years
    }).reset_index()
    
    # Calculate overall rate for each organization
    org_summary['overall_reappointment_rate'] = (
        org_summary['reappointment_count'] / org_summary['appointment_count'] * 100
    ).round(2)
    
    # Filter for organizations with sufficient activity
    min_appointments = 10
    active_orgs = org_summary[org_summary['appointment_count'] >= min_appointments].copy()
    
    print(f"  Organizations with ≥{min_appointments} total appointments: {len(active_orgs):,}")
    
    # Top organizations by overall reappointment rate
    print(f"\n  Top 15 organizations by overall reappointment rate:")
    top_rate_orgs = active_orgs.sort_values('overall_reappointment_rate', ascending=False).head(15)
    for i, (_, row) in enumerate(top_rate_orgs.iterrows(), 1):
        print(f"    {i:2d}. {row['org_clean']}: {row['overall_reappointment_rate']:.1f}% "
              f"({int(row['reappointment_count'])}/{int(row['appointment_count'])} appointments)")
    
    # Organizations with highest absolute reappointment counts
    print(f"\n  Top 15 organizations by total reappointment volume:")
    top_volume_orgs = active_orgs.sort_values('reappointment_count', ascending=False).head(15)
    for i, (_, row) in enumerate(top_volume_orgs.iterrows(), 1):
        print(f"    {i:2d}. {row['org_clean']}: {int(row['reappointment_count']):,} reappointments "
              f"({row['overall_reappointment_rate']:.1f}% of {int(row['appointment_count'])})")
    
    return active_orgs

def analyze_temporal_trends(rates_data):
    """Analyze temporal trends in reappointment rates."""
    print("\n📈 Analyzing temporal trends:")
    
    # Overall yearly trends
    yearly_summary = rates_data.groupby('year').agg({
        'appointment_count': 'sum',
        'reappointment_count': 'sum',
        'reappointment_rate': 'mean'
    }).reset_index()
    
    # Calculate overall rate for each year
    yearly_summary['yearly_overall_rate'] = (
        yearly_summary['reappointment_count'] / yearly_summary['appointment_count'] * 100
    ).round(2)
    
    print(f"  Year-over-year reappointment trends:")
    for _, row in yearly_summary.iterrows():
        print(f"    {int(row['year'])}: {row['yearly_overall_rate']:.1f}% "
              f"({int(row['reappointment_count']):,}/{int(row['appointment_count']):,} appointments)")
    
    # Calculate trend direction
    if len(yearly_summary) > 1:
        print(f"\n  Year-over-year rate changes:")
        for i in range(1, len(yearly_summary)):
            current_year = yearly_summary.iloc[i]
            previous_year = yearly_summary.iloc[i-1]
            rate_change = current_year['yearly_overall_rate'] - previous_year['yearly_overall_rate']
            direction = "↗️" if rate_change > 0 else "↘️" if rate_change < 0 else "➡️"
            print(f"    {int(previous_year['year'])} → {int(current_year['year'])}: {rate_change:+.1f} percentage points {direction}")
    
    # Identify organizations with strongest upward/downward trends
    print(f"\n  Organizations with strongest trends (≥5 years of data):")
    
    trend_analysis = []
    for org in rates_data['org_clean'].unique():
        org_data = rates_data[rates_data['org_clean'] == org].sort_values('year')
        if len(org_data) >= 5:  # At least 5 years of data
            # Simple linear trend calculation
            years = org_data['year'].values
            rates = org_data['reappointment_rate'].values
            trend_slope = np.polyfit(years, rates, 1)[0]  # Linear slope
            
            trend_analysis.append({
                'organization': org,
                'years_of_data': len(org_data),
                'trend_slope': trend_slope,
                'total_appointments': org_data['appointment_count'].sum(),
                'avg_rate': org_data['reappointment_rate'].mean()
            })
    
    if trend_analysis:
        trend_df = pd.DataFrame(trend_analysis)
        
        # Top increasing trends
        increasing_trends = trend_df.sort_values('trend_slope', ascending=False).head(5)
        print(f"    Top 5 increasing trends:")
        for i, (_, row) in enumerate(increasing_trends.iterrows(), 1):
            print(f"      {i}. {row['organization']}: +{row['trend_slope']:.2f} percentage points/year "
                  f"(avg {row['avg_rate']:.1f}%, {row['years_of_data']} years)")
        
        # Top decreasing trends
        decreasing_trends = trend_df.sort_values('trend_slope', ascending=True).head(5)
        print(f"    Top 5 decreasing trends:")
        for i, (_, row) in enumerate(decreasing_trends.iterrows(), 1):
            print(f"      {i}. {row['organization']}: {row['trend_slope']:.2f} percentage points/year "
                  f"(avg {row['avg_rate']:.1f}%, {row['years_of_data']} years)")
    
    return yearly_summary

def export_comprehensive_analysis(rates_data, active_orgs, yearly_summary, output_path):
    """Export comprehensive reappointment rate analysis."""
    print(f"\n💾 Exporting comprehensive analysis:")
    
    # Main output: detailed rates by org-year
    main_output = output_path / "step6_reappointment_rates.csv"
    rates_data.to_csv(main_output, index=False)
    print(f"  ✓ Saved detailed rates: {main_output}")
    
    # Organization summary
    org_summary_output = output_path / "step6_organization_summary.csv"
    active_orgs.to_csv(org_summary_output, index=False)
    print(f"  ✓ Saved organization summary: {org_summary_output}")
    
    # Yearly summary
    yearly_output = output_path / "step6_yearly_summary.csv"
    yearly_summary.to_csv(yearly_output, index=False)
    print(f"  ✓ Saved yearly summary: {yearly_output}")
    
    # Create pivot table for visualization
    pivot_rates = rates_data.pivot(index='org_clean', columns='year', values='reappointment_rate').fillna(0)
    pivot_output = output_path / "step6_reappointment_rates_pivot.csv"
    pivot_rates.to_csv(pivot_output)
    print(f"  ✓ Saved rates pivot table: {pivot_output}")
    
    # Summary statistics file
    summary_output = output_path / "step6_analysis_summary.txt"
    with open(summary_output, 'w') as f:
        f.write("STEP 6: REAPPOINTMENT RATES ANALYSIS SUMMARY\n")
        f.write("="*50 + "\n\n")
        f.write(f"Total org-year combinations: {len(rates_data):,}\n")
        f.write(f"Combinations with reappointments: {(rates_data['reappointment_count'] > 0).sum():,}\n")
        f.write(f"Average reappointment rate: {rates_data['reappointment_rate'].mean():.2f}%\n")
        f.write(f"Organizations with ≥10 appointments: {len(active_orgs):,}\n")
        f.write(f"Years analyzed: {rates_data['year'].min()}-{rates_data['year'].max()}\n")
    print(f"  ✓ Saved analysis summary: {summary_output}")

def calculate_rates():
    """Main function to calculate reappointment rates."""
    print("="*60)
    print("STEP 6: CALCULATING REAPPOINTMENT RATES")
    print("="*60)
    
    # Define paths
    input_path = Path("scripts/claudesonnet4/version2/execution4/analysis_data")
    step4_file = input_path / "step4_appointment_counts.csv"
    step5_file = input_path / "step5_reappointment_counts.csv"
    output_file = input_path / "step6_reappointment_rates.csv"
    
    # Validate input files
    if not validate_input_files(step4_file, step5_file):
        return False
    
    try:
        # Load and merge data from Steps 4 and 5
        merged_data = load_and_merge_data(step4_file, step5_file)
        if merged_data is None:
            return False
        
        # Calculate reappointment rates
        rates_data = calculate_reappointment_rates(merged_data)
        
        # Analyze top performing organizations
        active_orgs = analyze_top_performers(rates_data)
        
        # Analyze temporal trends
        yearly_summary = analyze_temporal_trends(rates_data)
        
        # Display sample of results
        print(f"\n📋 Sample of reappointment rates (first 10 rows):")
        sample_data = rates_data.head(10)[['org_clean', 'year', 'appointment_count', 
                                          'reappointment_count', 'reappointment_rate']]
        print(sample_data.to_string(index=False))
        
        # Export comprehensive analysis
        export_comprehensive_analysis(rates_data, active_orgs, yearly_summary, input_path)
        
        # Save main output file
        print(f"\n💾 Saving main output file: {output_file}")
        rates_data.to_csv(output_file, index=False)
        print(f"✓ Successfully saved: {len(rates_data):,} org-year combinations with rates")
        
        # Final validation
        try:
            verification_df = pd.read_csv(output_file)
            if len(verification_df) == len(rates_data) and len(verification_df.columns) == len(rates_data.columns):
                print("✓ File save verification successful")
                
                # Verify rate calculations
                sample_verification = verification_df.head()
                calculated_rates = (sample_verification['reappointment_count'] / 
                                  sample_verification['appointment_count'] * 100).round(2)
                if (calculated_rates == sample_verification['reappointment_rate']).all():
                    print("✓ Rate calculation verification successful")
                else:
                    print("⚠ Warning: Rate calculations may have errors")
            else:
                print("⚠ Warning: Saved file dimensions don't match processed data")
        except Exception as e:
            print(f"⚠ Warning: Could not verify saved file: {e}")
        
        print("\n" + "="*60)
        print("STEP 6 COMPLETED SUCCESSFULLY")
        print("="*60)
        print(f"Main Output: {output_file}")
        print(f"Calculated reappointment rates for {len(rates_data):,} org-year combinations")
        print(f"Average reappointment rate: {rates_data['reappointment_rate'].mean():.1f}%")
        print("Ready for Step 7: Identify organizations with maximum reappointment rates")
        
        return True
        
    except Exception as e:
        print(f"✗ Error calculating reappointment rates: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = calculate_rates()
    if not success:
        print("\n❌ Step 6 failed. Please check the errors above and retry.")
        sys.exit(1)
    else:
        print("\n✅ Step 6 completed successfully!")