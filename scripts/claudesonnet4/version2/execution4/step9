#!/usr/bin/env python3
"""
Step 9: Linear Regression Analysis of Reappointment Trends
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

This script runs comprehensive linear regression analysis on the annual reappointment 
proportions to assess trend direction and statistical significance.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import pearsonr
import seaborn as sns
from pathlib import Path
import sys
import os

def validate_input_file(input_file):
    """Validate that the Step 8 input file exists and has required columns."""
    if not input_file.exists():
        print(f"‚úó Input file not found: {input_file}")
        print("Please run Step 8 first to create annual proportions.")
        return False
    
    try:
        # Read and validate required columns
        df = pd.read_csv(input_file)
        required_columns = ['year', 'reappointment_proportion']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"‚úó Missing required columns: {missing_columns}")
            print(f"Available columns: {list(df.columns)}")
            return False
        
        print(f"‚úì Input file validated: {input_file}")
        print(f"  Records: {len(df):,}")
        print(f"  Required columns present: {required_columns}")
        return True
        
    except Exception as e:
        print(f"‚úó Error reading input file: {e}")
        return False

def perform_linear_regression(df):
    """Perform comprehensive linear regression analysis on annual proportions."""
    print("\nüìà Performing linear regression analysis:")
    
    # Prepare data for regression
    years = df['year'].values
    proportions = df['reappointment_proportion'].values
    
    print(f"  Data points: {len(years)} years ({years.min():.0f}-{years.max():.0f})")
    print(f"  Proportion range: {proportions.min():.2f}% - {proportions.max():.2f}%")
    
    # Perform linear regression using scipy.stats.linregress
    slope, intercept, r_value, p_value, std_err = stats.linregress(years, proportions)
    
    # Additional statistics
    n = len(years)
    degrees_freedom = n - 2
    t_statistic = slope / std_err
    
    # Confidence intervals for slope (95% confidence)
    t_critical = stats.t.ppf(0.975, degrees_freedom)  # Two-tailed, 95% CI
    slope_ci_lower = slope - t_critical * std_err
    slope_ci_upper = slope + t_critical * std_err
    
    # Calculate fitted values and residuals
    fitted_values = slope * years + intercept
    residuals = proportions - fitted_values
    
    # Calculate additional regression statistics
    ss_total = np.sum((proportions - np.mean(proportions)) ** 2)
    ss_residual = np.sum(residuals ** 2)
    ss_regression = ss_total - ss_residual
    
    # Mean squared error and standard error of estimate
    mse = ss_residual / degrees_freedom
    se_estimate = np.sqrt(mse)
    
    # F-statistic for overall model significance
    f_statistic = (ss_regression / 1) / (ss_residual / degrees_freedom)
    f_p_value = 1 - stats.f.cdf(f_statistic, 1, degrees_freedom)
    
    print(f"\n  Regression Results:")
    print(f"    Slope (Œ≤‚ÇÅ): {slope:.4f} percentage points per year")
    print(f"    Intercept (Œ≤‚ÇÄ): {intercept:.4f}")
    print(f"    R-squared (R¬≤): {r_value**2:.4f} ({r_value**2*100:.1f}% of variance explained)")
    print(f"    Correlation coefficient (r): {r_value:.4f}")
    print(f"    Standard error of slope: {std_err:.4f}")
    print(f"    95% Confidence interval for slope: [{slope_ci_lower:.4f}, {slope_ci_upper:.4f}]")
    
    return {
        'slope': slope,
        'intercept': intercept,
        'r_value': r_value,
        'r_squared': r_value**2,
        'p_value': p_value,
        'std_err': std_err,
        'n_observations': n,
        'degrees_freedom': degrees_freedom,
        't_statistic': t_statistic,
        'slope_ci_lower': slope_ci_lower,
        'slope_ci_upper': slope_ci_upper,
        'fitted_values': fitted_values,
        'residuals': residuals,
        'se_estimate': se_estimate,
        'f_statistic': f_statistic,
        'f_p_value': f_p_value
    }

def assess_statistical_significance(regression_results):
    """Assess the statistical significance of the regression results."""
    print(f"\nüî¨ Statistical Significance Assessment:")
    
    slope = regression_results['slope']
    p_value = regression_results['p_value']
    r_squared = regression_results['r_squared']
    f_p_value = regression_results['f_p_value']
    slope_ci_lower = regression_results['slope_ci_lower']
    slope_ci_upper = regression_results['slope_ci_upper']
    
    # Significance levels
    alpha_001 = 0.001  # 99.9% confidence
    alpha_01 = 0.01    # 99% confidence  
    alpha_05 = 0.05    # 95% confidence
    alpha_10 = 0.10    # 90% confidence
    
    print(f"  Hypothesis Testing:")
    print(f"    H‚ÇÄ: No trend exists (slope = 0)")
    print(f"    H‚ÇÅ: A trend exists (slope ‚â† 0)")
    print(f"    Test statistic (t): {regression_results['t_statistic']:.4f}")
    print(f"    P-value: {p_value:.6f}")
    
    # Determine significance level
    if p_value < alpha_001:
        significance = "highly significant (p < 0.001) ***"
        confidence = "99.9%"
    elif p_value < alpha_01:
        significance = "very significant (p < 0.01) **"
        confidence = "99%"
    elif p_value < alpha_05:
        significance = "significant (p < 0.05) *"
        confidence = "95%"
    elif p_value < alpha_10:
        significance = "marginally significant (p < 0.10)"
        confidence = "90%"
    else:
        significance = "not significant (p ‚â• 0.10)"
        confidence = "< 90%"
    
    print(f"    Result: The trend is {significance}")
    print(f"    Confidence level: {confidence}")
    
    # Practical significance assessment
    print(f"\n  Practical Significance:")
    print(f"    Annual change: {slope:+.3f} percentage points per year")
    
    # Check if confidence interval includes zero
    includes_zero = slope_ci_lower <= 0 <= slope_ci_upper
    print(f"    95% CI includes zero: {'Yes' if includes_zero else 'No'}")
    
    if not includes_zero:
        if slope > 0:
            direction_certainty = "We can be 95% confident the trend is increasing"
        else:
            direction_certainty = "We can be 95% confident the trend is decreasing"
    else:
        direction_certainty = "The trend direction is not statistically certain"
    
    print(f"    Interpretation: {direction_certainty}")
    
    # Effect size assessment based on R¬≤
    if r_squared >= 0.64:
        effect_size = "large effect (R¬≤ ‚â• 0.64)"
    elif r_squared >= 0.36:
        effect_size = "medium effect (R¬≤ ‚â• 0.36)"
    elif r_squared >= 0.16:
        effect_size = "small effect (R¬≤ ‚â• 0.16)"
    else:
        effect_size = "negligible effect (R¬≤ < 0.16)"
    
    print(f"    Effect size: {effect_size}")
    
    # Overall model significance
    print(f"\n  Overall Model Assessment:")
    print(f"    F-statistic: {regression_results['f_statistic']:.4f}")
    print(f"    Model p-value: {f_p_value:.6f}")
    
    model_significant = f_p_value < alpha_05
    print(f"    Model significance: {'Significant' if model_significant else 'Not significant'}")
    
    return {
        'is_significant': p_value < alpha_05,
        'significance_level': significance,
        'confidence_level': confidence,
        'direction_certain': not includes_zero,
        'effect_size': effect_size,
        'model_significant': model_significant
    }

def analyze_trend_characteristics(df, regression_results):
    """Analyze specific characteristics of the trend."""
    print(f"\nüìä Trend Characteristics Analysis:")
    
    years = df['year'].values
    proportions = df['reappointment_proportion'].values
    slope = regression_results['slope']
    fitted_values = regression_results['fitted_values']
    
    # Trend direction and magnitude
    if slope > 0:
        trend_direction = "increasing"
        trend_emoji = "üìà"
    elif slope < 0:
        trend_direction = "decreasing"
        trend_emoji = "üìâ"
    else:
        trend_direction = "stable"
        trend_emoji = "‚û°Ô∏è"
    
    print(f"  Trend Direction: {trend_direction.upper()} {trend_emoji}")
    
    # Calculate total predicted change over the study period
    study_period = years.max() - years.min()
    total_predicted_change = slope * study_period
    
    print(f"  Magnitude Analysis:")
    print(f"    Annual rate of change: {slope:+.3f} percentage points per year")
    print(f"    Total change over {study_period:.0f} years: {total_predicted_change:+.2f} percentage points")
    
    # Calculate actual vs predicted change
    actual_start = proportions[0]
    actual_end = proportions[-1]
    actual_change = actual_end - actual_start
    
    predicted_start = fitted_values[0]
    predicted_end = fitted_values[-1]
    predicted_change = predicted_end - predicted_start
    
    print(f"    Actual change: {actual_change:+.2f} percentage points")
    print(f"    Model predicted change: {predicted_change:+.2f} percentage points")
    print(f"    Difference (actual - predicted): {actual_change - predicted_change:+.2f} percentage points")
    
    # Projected future values (if trend continues)
    future_years = [2025, 2026, 2027, 2030]
    print(f"\n  Future Projections (if current trend continues):")
    for future_year in future_years:
        projected_value = slope * future_year + regression_results['intercept']
        years_ahead = future_year - years.max()
        print(f"    {future_year}: {projected_value:.1f}% ({years_ahead} years ahead)")
        
        # Warning for extreme projections
        if projected_value < 0 or projected_value > 100:
            print(f"      ‚ö† Warning: Projection outside realistic range (0-100%)")
    
    # Acceleration/deceleration analysis
    print(f"\n  Trend Consistency:")
    
    # Split data into two halves and compare slopes
    midpoint = len(years) // 2
    
    if len(years) >= 6:  # Need sufficient data for split analysis
        early_years = years[:midpoint+1]
        early_props = proportions[:midpoint+1]
        later_years = years[midpoint:]
        later_props = proportions[midpoint:]
        
        early_slope = stats.linregress(early_years, early_props)[0]
        later_slope = stats.linregress(later_years, later_props)[0]
        
        print(f"    Early period slope: {early_slope:+.3f} pp/year")
        print(f"    Later period slope: {later_slope:+.3f} pp/year")
        
        if abs(later_slope - early_slope) > abs(early_slope) * 0.5:  # 50% change threshold
            if later_slope > early_slope:
                acceleration = "accelerating"
            else:
                acceleration = "decelerating"
            print(f"    Trend appears to be {acceleration}")
        else:
            print(f"    Trend appears relatively consistent")
    
    return {
        'direction': trend_direction,
        'annual_change': slope,
        'total_change': total_predicted_change,
        'actual_change': actual_change,
        'predicted_change': predicted_change
    }

def create_regression_visualization(df, regression_results, output_path):
    """Create comprehensive regression visualization."""
    print(f"\nüìä Creating regression visualization:")
    
    # Set up the plot style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # Create a 2x2 subplot layout
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    years = df['year'].values
    proportions = df['reappointment_proportion'].values
    fitted_values = regression_results['fitted_values']
    residuals = regression_results['residuals']
    
    # Plot 1: Main regression plot
    ax1.scatter(years, proportions, color='#2E86C1', s=80, alpha=0.7, edgecolors='black', linewidth=1)
    ax1.plot(years, fitted_values, color='#E74C3C', linewidth=3, label=f'Regression Line')
    
    # Add confidence interval
    slope = regression_results['slope']
    intercept = regression_results['intercept']
    se_estimate = regression_results['se_estimate']
    
    # Calculate prediction intervals (approximate)
    t_critical = stats.t.ppf(0.975, regression_results['degrees_freedom'])
    margin_error = t_critical * se_estimate
    
    upper_bound = fitted_values + margin_error
    lower_bound = fitted_values - margin_error
    
    ax1.fill_between(years, lower_bound, upper_bound, alpha=0.2, color='#E74C3C', label='95% Prediction Interval')
    
    ax1.set_xlabel('Year', fontweight='bold')
    ax1.set_ylabel('Reappointment Proportion (%)', fontweight='bold')
    ax1.set_title(f'Linear Regression: Annual Reappointment Proportions\n'
                  f'Slope = {slope:+.3f} pp/year, R¬≤ = {regression_results["r_squared"]:.3f}, '
                  f'p = {regression_results["p_value"]:.4f}', fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # Add data point labels
    for i, (year, prop) in enumerate(zip(years, proportions)):
        ax1.annotate(f'{prop:.1f}%', (year, prop), xytext=(0, 10), 
                    textcoords='offset points', ha='center', fontsize=9, alpha=0.8)
    
    # Plot 2: Residuals vs Fitted
    ax2.scatter(fitted_values, residuals, color='#28B463', s=60, alpha=0.7)
    ax2.axhline(y=0, color='#E74C3C', linestyle='--', alpha=0.7)
    ax2.set_xlabel('Fitted Values (%)', fontweight='bold')
    ax2.set_ylabel('Residuals (%)', fontweight='bold')
    ax2.set_title('Residuals vs Fitted Values\n(Check for Homoscedasticity)', fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Q-Q plot for normality
    stats.probplot(residuals, dist="norm", plot=ax3)
    ax3.set_title('Q-Q Plot: Residual Normality Check', fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Residuals vs Year (temporal patterns)
    ax4.scatter(years, residuals, color='#F39C12', s=60, alpha=0.7)
    ax4.plot(years, residuals, color='#F39C12', alpha=0.5, linewidth=1)
    ax4.axhline(y=0, color='#E74C3C', linestyle='--', alpha=0.7)
    ax4.set_xlabel('Year', fontweight='bold')
    ax4.set_ylabel('Residuals (%)', fontweight='bold')
    ax4.set_title('Residuals vs Year\n(Check for Temporal Patterns)', fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    # Add overall statistics
    fig.suptitle('Linear Regression Analysis: New Brunswick Government Reappointment Trends (2013-2024)', 
                 fontsize=16, fontweight='bold', y=0.98)
    
    # Add summary text
    r_squared = regression_results['r_squared']
    p_value = regression_results['p_value']
    significance = "Significant" if p_value < 0.05 else "Not Significant"
    
    fig.text(0.02, 0.02, f"Model Summary: R¬≤ = {r_squared:.3f} | p-value = {p_value:.4f} | {significance} | "
                          f"n = {regression_results['n_observations']} years", 
             fontsize=12, alpha=0.8)
    
    # Adjust layout
    plt.tight_layout()
    plt.subplots_adjust(top=0.93, bottom=0.07)
    
    # Save the plot
    output_file = output_path / "step9_regression_analysis.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"  ‚úì Saved regression visualization: {output_file}")
    
    plt.show()
    plt.close()

def perform_diagnostic_tests(regression_results):
    """Perform diagnostic tests on the regression model."""
    print(f"\nüî¨ Regression Diagnostic Tests:")
    
    residuals = regression_results['residuals']
    n = regression_results['n_observations']
    
    # Test 1: Durbin-Watson test for autocorrelation (approximate)
    diff_residuals = np.diff(residuals)
    dw_statistic = np.sum(diff_residuals**2) / np.sum(residuals**2)
    
    print(f"  Autocorrelation Test:")
    print(f"    Durbin-Watson statistic: {dw_statistic:.3f}")
    if 1.5 < dw_statistic < 2.5:
        dw_interpretation = "No significant autocorrelation"
    elif dw_statistic <= 1.5:
        dw_interpretation = "Positive autocorrelation detected"
    else:
        dw_interpretation = "Negative autocorrelation detected"
    print(f"    Interpretation: {dw_interpretation}")
    
    # Test 2: Shapiro-Wilk test for residual normality
    if n >= 3:  # Need at least 3 observations
        shapiro_stat, shapiro_p = stats.shapiro(residuals)
        print(f"\n  Normality Test (Shapiro-Wilk):")
        print(f"    Test statistic: {shapiro_stat:.3f}")
        print(f"    P-value: {shapiro_p:.3f}")
        
        normal_assumption = shapiro_p > 0.05
        print(f"    Result: Residuals {'appear' if normal_assumption else 'do not appear'} normally distributed")
    
    # Test 3: Homoscedasticity assessment
    fitted_values = regression_results['fitted_values']
    
    # Simple test: correlation between absolute residuals and fitted values
    abs_residuals = np.abs(residuals)
    homo_corr, homo_p = pearsonr(fitted_values, abs_residuals)
    
    print(f"\n  Homoscedasticity Assessment:")
    print(f"    Correlation (|residuals| vs fitted): {homo_corr:.3f}")
    print(f"    P-value: {homo_p:.3f}")
    
    homoscedastic = abs(homo_corr) < 0.3 and homo_p > 0.05
    print(f"    Result: {'Homoscedastic' if homoscedastic else 'Heteroscedastic'} (equal variance assumption)")
    
    # Overall model validity assessment
    print(f"\n  Model Validity Summary:")
    validity_score = 0
    total_tests = 3
    
    if 1.5 < dw_statistic < 2.5:
        validity_score += 1
    if n < 3 or shapiro_p > 0.05:  # Give benefit of doubt if can't test
        validity_score += 1
    if homoscedastic:
        validity_score += 1
    
    validity_percentage = (validity_score / total_tests) * 100
    
    if validity_percentage >= 100:
        validity_assessment = "Excellent - All assumptions met"
    elif validity_percentage >= 67:
        validity_assessment = "Good - Most assumptions met"
    elif validity_percentage >= 33:
        validity_assessment = "Fair - Some assumption violations"
    else:
        validity_assessment = "Poor - Multiple assumption violations"
    
    print(f"    Overall assessment: {validity_assessment} ({validity_score}/{total_tests} tests passed)")
    
    return {
        'durbin_watson': dw_statistic,
        'shapiro_stat': shapiro_stat if n >= 3 else None,
        'shapiro_p': shapiro_p if n >= 3 else None,
        'homoscedasticity_corr': homo_corr,
        'homoscedasticity_p': homo_p,
        'validity_score': validity_score,
        'validity_percentage': validity_percentage
    }

def export_regression_results(df, regression_results, significance_assessment, trend_analysis, diagnostics, output_path):
    """Export comprehensive regression analysis results."""
    print(f"\nüíæ Exporting regression analysis results:")
    
    # Main results file with detailed statistics
    results_output = output_path / "step9_regression_results.txt"
    with open(results_output, 'w') as f:
        f.write("STEP 9: LINEAR REGRESSION ANALYSIS RESULTS\n")
        f.write("="*60 + "\n\n")
        
        f.write("RESEARCH QUESTION FINAL ANSWER:\n")
        f.write("-"*35 + "\n")
        f.write("Question: Is the reappointment trend increasing or declining over the past 12 years?\n\n")
        
        slope = regression_results['slope']
        if slope > 0:
            trend_answer = "INCREASING"
        elif slope < 0:
            trend_answer = "DECREASING"
        else:
            trend_answer = "STABLE"
        
        f.write(f"ANSWER: {trend_answer}\n")
        f.write(f"Evidence: {slope:+.3f} percentage points per year\n")
        f.write(f"Statistical significance: {significance_assessment['significance_level']}\n")
        f.write(f"Confidence in direction: {'95%+ certain' if significance_assessment['direction_certain'] else 'Uncertain'}\n\n")
        
        f.write("DETAILED REGRESSION STATISTICS:\n")
        f.write("-"*35 + "\n")
        f.write(f"Slope (Œ≤‚ÇÅ): {regression_results['slope']:.6f} pp/year\n")
        f.write(f"Intercept (Œ≤‚ÇÄ): {regression_results['intercept']:.6f}\n")
        f.write(f"R-squared: {regression_results['r_squared']:.6f}\n")
        f.write(f"Correlation coefficient: {regression_results['r_value']:.6f}\n")
        f.write(f"P-value: {regression_results['p_value']:.6f}\n")
        f.write(f"Standard error of slope: {regression_results['std_err']:.6f}\n")
        f.write(f"95% CI for slope: [{regression_results['slope_ci_lower']:.6f}, {regression_results['slope_ci_upper']:.6f}]\n")
        f.write(f"Sample size: {regression_results['n_observations']} years\n")
        f.write(f"Degrees of freedom: {regression_results['degrees_freedom']}\n\n")
        
        f.write("MODEL DIAGNOSTICS:\n")
        f.write("-"*18 + "\n")
        f.write(f"Durbin-Watson statistic: {diagnostics['durbin_watson']:.3f}\n")
        if diagnostics['shapiro_p'] is not None:
            f.write(f"Shapiro-Wilk p-value: {diagnostics['shapiro_p']:.3f}\n")
        f.write(f"Homoscedasticity correlation: {diagnostics['homoscedasticity_corr']:.3f}\n")
        f.write(f"Model validity: {diagnostics['validity_percentage']:.0f}% of assumptions met\n\n")
        
        f.write("PRACTICAL INTERPRETATION:\n")
        f.write("-"*25 + "\n")
        f.write(f"Annual rate of change: {trend_analysis['annual_change']:+.3f} percentage points\n")
        f.write(f"Total change over study period: {trend_analysis['total_change']:+.2f} percentage points\n")
        f.write(f"Effect size: {significance_assessment['effect_size']}\n")
        
        # Future projections
        f.write(f"\nFUTURE PROJECTIONS (if trend continues):\n")
        f.write(f"2025: {slope * 2025 + regression_results['intercept']:.1f}%\n")
        f.write(f"2030: {slope * 2030 + regression_results['intercept']:.1f}%\n")
    
    print(f"  ‚úì Saved detailed results: {results_output}")
    
    # CSV with fitted values and residuals
    analysis_df = df.copy()
    analysis_df['fitted_values'] = regression_results['fitted_values']
    analysis_df['residuals'] = regression_results['residuals']
    
    csv_output = output_path / "step9_regression_data.csv"
    analysis_df.to_csv(csv_output, index=False)
    print(f"  ‚úì Saved regression data: {csv_output}")
    
    # Summary statistics CSV
    summary_stats = pd.DataFrame({
        'Statistic': ['Slope', 'Intercept', 'R-squared', 'P-value', 'Sample_Size', 
                     'CI_Lower', 'CI_Upper', 'Standard_Error'],
        'Value': [regression_results['slope'], regression_results['intercept'], 
                 regression_results['r_squared'], regression_results['p_value'],
                 regression_results['n_observations'], regression_results['slope_ci_lower'],
                 regression_results['slope_ci_upper'], regression_results['std_err']]
    })
    
    stats_output = output_path / "step9_regression_summary.csv"
    summary_stats.to_csv(stats_output, index=False)
    print(f"  ‚úì Saved summary statistics: {stats_output}")

def run_regression_analysis():
    """Main function to run comprehensive linear regression analysis."""
    print("="*60)
    print("STEP 9: LINEAR REGRESSION ANALYSIS OF REAPPOINTMENT TRENDS")
    print("="*60)
    
    # Define paths
    input_path = Path("scripts/claudesonnet4/version2/execution4/analysis_data")
    input_file = input_path / "step8_annual_proportions.csv"
    
    # Validate input file
    if not validate_input_file(input_file):
        return False
    
    try:
        # Load annual proportions data
        print(f"\nüìÇ Loading annual proportions data...")
        df = pd.read_csv(input_file)
        print(f"‚úì Loaded dataset: {len(df):,} years")
        
        # Display data summary
        print(f"\nüìã Data Summary:")
        print(f"  Years: {df['year'].min():.0f} - {df['year'].max():.0f}")
        print(f"  Reappointment proportion range: {df['reappointment_proportion'].min():.2f}% - {df['reappointment_proportion'].max():.2f}%")
        print(f"  Mean proportion: {df['reappointment_proportion'].mean():.2f}%")
        print(f"  Standard deviation: {df['reappointment_proportion'].std():.2f}%")
        
        # Perform linear regression
        regression_results = perform_linear_regression(df)
        
        # Assess statistical significance
        significance_assessment = assess_statistical_significance(regression_results)
        
        # Analyze trend characteristics
        trend_analysis = analyze_trend_characteristics(df, regression_results)
        
        # Perform diagnostic tests
        diagnostics = perform_diagnostic_tests(regression_results)
        
        # Create visualization
        create_regression_visualization(df, regression_results, input_path)
        
        # Export comprehensive results
        export_regression_results(df, regression_results, significance_assessment, trend_analysis, diagnostics, input_path)
        
        # Display final conclusions
        print(f"\n" + "="*60)
        print("FINAL RESEARCH QUESTION CONCLUSIONS")
        print("="*60)
        
        slope = regression_results['slope']
        p_value = regression_results['p_value']
        r_squared = regression_results['r_squared']
        
        print(f"üîç RESEARCH QUESTION: Is the reappointment trend increasing or declining?")
        
        if slope > 0:
            trend_conclusion = "INCREASING üìà"
        elif slope < 0:
            trend_conclusion = "DECREASING üìâ"
        else:
            trend_conclusion = "STABLE ‚û°Ô∏è"
        
        print(f"üìä ANSWER: The trend is {trend_conclusion}")
        print(f"   Evidence: {slope:+.3f} percentage points per year")
        print(f"   Statistical significance: {significance_assessment['significance_level']}")
        print(f"   Model explains {r_squared*100:.1f}% of the variance")
        
        # Confidence in the result
        if significance_assessment['is_significant'] and significance_assessment['direction_certain']:
            confidence_level = "HIGH CONFIDENCE"
            confidence_emoji = "‚úÖ"
        elif significance_assessment['is_significant']:
            confidence_level = "MODERATE CONFIDENCE"
            confidence_emoji = "‚ö†Ô∏è"
        else:
            confidence_level = "LOW CONFIDENCE"
            confidence_emoji = "‚ùå"
        
        print(f"üéØ CONFIDENCE LEVEL: {confidence_level} {confidence_emoji}")
        
        if significance_assessment['direction_certain']:
            print(f"   We can be 95% confident the trend is {trend_analysis['direction']}")
        else:
            print(f"   The trend direction is not statistically certain")
        
        # Practical implications
        total_change = trend_analysis['total_change']
        print(f"\nüí° PRACTICAL IMPLICATIONS:")
        print(f"   Total change over 12 years: {total_change:+.2f} percentage points")
        
        if abs(total_change) >= 10:
            magnitude = "SUBSTANTIAL"
        elif abs(total_change) >= 5:
            magnitude = "MODERATE"
        else:
            magnitude = "MINIMAL"
        
        print(f"   Magnitude of change: {magnitude}")
        
        # Future outlook
        future_2030 = slope * 2030 + regression_results['intercept']
        print(f"   Projected 2030 rate (if trend continues): {future_2030:.1f}%")
        
        if future_2030 < 0 or future_2030 > 100:
            print(f"   ‚ö†Ô∏è Warning: Future projection outside realistic range")
        
        print("\n" + "="*60)
        print("STEP 9 COMPLETED SUCCESSFULLY")
        print("="*60)
        print(f"‚úÖ Comprehensive regression analysis complete")
        print(f"‚úÖ Research question definitively answered with statistical evidence")
        print(f"‚úÖ All outputs saved to analysis_data folder")
        print("\nüéâ ANALYSIS PIPELINE COMPLETE! üéâ")
        
        return True
        
    except Exception as e:
        print(f"‚úó Error in regression analysis: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = run_regression_analysis()
    if not success:
        print("\n‚ùå Step 9 failed. Please check the errors above and retry.")
        sys.exit(1)
    else:
        print("\n‚úÖ Step 9 completed successfully!")
        print("üèÜ COMPLETE ANALYSIS PIPELINE FINISHED! üèÜ")