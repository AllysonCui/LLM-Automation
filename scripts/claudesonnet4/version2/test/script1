import pandas as pd
import numpy as np
from pathlib import Path
import os

def combine_appointment_datasets():
    """
    Step 1: Combine 12 New Brunswick government appointment CSV files from 2013-2024
    
    This function:
    1. Reads all appointment CSV files from the raw_data directory
    2. Standardizes column names and data types across years
    3. Adds a year column for tracking
    4. Combines all datasets into a single DataFrame
    5. Saves the combined dataset for further analysis
    """
    
    # Define paths
    raw_data_path = Path("raw_data")
    output_dir = Path("steps/claudesonnet4/version2/analysis_data")
    
    # Create output directory if it doesn't exist
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=== Step 1: Combining New Brunswick Appointment Datasets (2013-2024) ===")
    print(f"Reading from: {raw_data_path}")
    print(f"Saving to: {output_dir}")
    
    # Initialize list to store DataFrames
    all_datasets = []
    years_processed = []
    
    # Process each year from 2013 to 2024
    for year in range(2013, 2025):
        file_path = raw_data_path / f"appointments_{year}.csv"
        
        try:
            # Check if file exists
            if not file_path.exists():
                print(f"WARNING: File not found - {file_path}")
                continue
            
            # Read CSV file
            print(f"Processing {file_path}...")
            df = pd.read_csv(file_path)
            
            # Add year column for tracking
            df['year'] = year
            
            # Store original row count for validation
            original_rows = len(df)
            
            # Basic data validation
            if df.empty:
                print(f"WARNING: Empty dataset for year {year}")
                continue
            
            # Print dataset info
            print(f"  - Year {year}: {original_rows} appointments loaded")
            print(f"  - Columns: {list(df.columns)}")
            
            # Handle potential column name variations
            # Standardize common column name variations
            column_mapping = {
                'organization': 'org',
                'Organisation': 'org',
                'Organization': 'org',
                're_appointed': 'reappointed',
                'reappointed_flag': 'reappointed',
                'Name': 'name',
                'Position': 'position',
                'Org': 'org'
            }
            
            # Apply column name standardization
            df = df.rename(columns=column_mapping)
            
            # Handle reappointed column data type variations
            if 'reappointed' in df.columns:
                # Convert various representations to boolean
                df['reappointed'] = df['reappointed'].astype(str).str.lower()
                df['reappointed'] = df['reappointed'].map({
                    'true': True,
                    'false': False,
                    '1': True,
                    '0': False,
                    'yes': True,
                    'no': False,
                    'y': True,
                    'n': False
                })
                
                # Count reappointments for validation
                reappointment_count = df['reappointed'].sum() if df['reappointed'].notna().any() else 0
                print(f"  - Reappointments in {year}: {reappointment_count}")
            else:
                print(f"  - WARNING: No 'reappointed' column found in {year} data")
            
            # Add to collection
            all_datasets.append(df)
            years_processed.append(year)
            
        except Exception as e:
            print(f"ERROR processing {file_path}: {str(e)}")
            continue
    
    # Combine all datasets
    if not all_datasets:
        raise ValueError("No valid datasets found to combine!")
    
    print(f"\n=== Combining {len(all_datasets)} datasets ===")
    
    # Concatenate all DataFrames
    combined_df = pd.concat(all_datasets, ignore_index=True, sort=False)
    
    # Data validation and summary statistics
    total_appointments = len(combined_df)
    years_span = f"{min(years_processed)}-{max(years_processed)}"
    unique_years = combined_df['year'].nunique()
    
    print(f"\n=== Combined Dataset Summary ===")
    print(f"Total appointments: {total_appointments:,}")
    print(f"Years covered: {years_span} ({unique_years} years)")
    print(f"Years processed: {sorted(years_processed)}")
    
    # Column summary
    print(f"\nFinal columns ({len(combined_df.columns)}):")
    for col in sorted(combined_df.columns):
        non_null_count = combined_df[col].notna().sum()
        null_count = combined_df[col].isna().sum()
        print(f"  - {col}: {non_null_count:,} non-null, {null_count:,} null")
    
    # Reappointment summary
    if 'reappointed' in combined_df.columns:
        total_reappointments = combined_df['reappointed'].sum()
        reappointment_rate = (total_reappointments / total_appointments) * 100
        print(f"\nReappointment Summary:")
        print(f"Total reappointments: {total_reappointments:,}")
        print(f"Overall reappointment rate: {reappointment_rate:.2f}%")
        
        # Yearly reappointment breakdown
        yearly_summary = combined_df.groupby('year')['reappointed'].agg(['count', 'sum']).reset_index()
        yearly_summary['rate'] = (yearly_summary['sum'] / yearly_summary['count']) * 100
        print(f"\nYearly Reappointment Rates:")
        for _, row in yearly_summary.iterrows():
            print(f"  {int(row['year'])}: {row['sum']}/{row['count']} ({row['rate']:.1f}%)")
    
    # Save combined dataset
    output_file = output_dir / "step1_combined_appointments.csv"
    combined_df.to_csv(output_file, index=False)
    print(f"\n=== Step 1 Complete ===")
    print(f"Combined dataset saved to: {output_file}")
    print(f"Ready for Step 2: Key columns extraction")
    
    return combined_df

# Execute the function
if __name__ == "__main__":
    try:
        combined_data = combine_appointment_datasets()
        print(f"\nStep 1 successful! Combined {len(combined_data):,} appointment records.")
    except Exception as e:
        print(f"CRITICAL ERROR in Step 1: {str(e)}")
        raise