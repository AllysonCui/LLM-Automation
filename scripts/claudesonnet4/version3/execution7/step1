#!/usr/bin/env python3
"""
New Brunswick Government Reappointment Analysis
Research Question: Which government branch in New Brunswick most frequently reappoints 
past appointees, and is this trend increasing or declining over the past 12 years?

Author: Claude Sonnet 4
Version: 3
Execution: 7
"""

import pandas as pd
import numpy as np
from scipy import stats
from pathlib import Path
import os
import sys
from datetime import datetime

def setup_directories():
    """Create necessary directories for analysis outputs."""
    output_dir = Path("scripts/claudesonnet4/version3/execution7/analysis_data")
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir

def validate_file_exists(filepath):
    """Validate that a file exists and is readable."""
    if not Path(filepath).exists():
        raise FileNotFoundError(f"Required file not found: {filepath}")
    return True

def load_and_combine_datasets(raw_data_dir, output_dir):
    """
    Step 1: Combine all 12 CSV files from 2013-2024
    """
    print("Step 1: Loading and combining datasets...")
    
    combined_data = []
    years = range(2013, 2025)  # 2013-2024 inclusive
    
    for year in years:
        filepath = Path(raw_data_dir) / f"appointments_{year}.csv"
        
        try:
            validate_file_exists(filepath)
            df = pd.read_csv(filepath)
            df['year'] = year  # Add year column
            combined_data.append(df)
            print(f"  ✓ Loaded {len(df)} records from {year}")
        except FileNotFoundError:
            print(f"  ⚠ Warning: File not found for year {year}")
            continue
        except Exception as e:
            print(f"  ✗ Error loading {year}: {e}")
            continue
    
    if not combined_data:
        raise ValueError("No data files could be loaded!")
    
    # Combine all dataframes
    combined_df = pd.concat(combined_data, ignore_index=True)
    
    # Save combined dataset
    output_file = output_dir / "step1_combined_appointments.csv"
    combined_df.to_csv(output_file, index=False)
    
    print(f"  ✓ Combined dataset saved: {len(combined_df)} total records")
    print(f"  ✓ Years covered: {sorted(combined_df['year'].unique())}")
    
    return combined_df

def extract_key_columns(combined_df, output_dir):
    """
    Step 2: Extract and retain key columns: reappointed, name, position, org, year
    """
    print("\nStep 2: Extracting key columns...")
    
    # Define required columns
    required_columns = ['reappointed', 'name', 'position', 'org', 'year']
    
    # Check if all required columns exist
    missing_columns = [col for col in required_columns if col not in combined_df.columns]
    if missing_columns:
        print(f"  ⚠ Missing columns: {missing_columns}")
        # Show available columns for debugging
        print(f"  Available columns: {list(combined_df.columns)}")
    
    # Extract available columns
    available_columns = [col for col in required_columns if col in combined_df.columns]
    key_data = combined_df[available_columns].copy()
    
    # Clean and standardize data
    key_data['name'] = key_data['name'].astype(str).str.strip().str.upper()
    key_data['position'] = key_data['position'].astype(str).str.strip()
    key_data['org'] = key_data['org'].astype(str).str.strip()
    
    # Handle reappointed column - convert to boolean if needed
    if 'reappointed' in key_data.columns:
        if key_data['reappointed'].dtype == 'object':
            # Convert text values to boolean
            key_data['reappointed'] = key_data['reappointed'].astype(str).str.lower().isin(['true', 'yes', '1'])
        key_data['reappointed'] = key_data['reappointed'].astype(bool)
    
    # Remove rows with missing critical data
    initial_count = len(key_data)
    key_data = key_data.dropna(subset=['name', 'org', 'year'])
    final_count = len(key_data)
    
    print(f"  ✓ Extracted {len(available_columns)} key columns")
    print(f"  ✓ Cleaned data: {initial_count} -> {final_count} records")
    
    # Save key columns data
    output_file = output_dir / "step2_key_columns_data.csv"
    key_data.to_csv(output_file, index=False)
    
    return key_data

def mark_reappointments(key_data, output_dir):
    """
    Step 3: Mark reappointed as true for repeated name-position-org combinations
    except for the first appearance
    """
    print("\nStep 3: Marking reappointments based on repeated combinations...")
    
    # Sort by year to ensure chronological order
    key_data_sorted = key_data.sort_values(['name', 'position', 'org', 'year']).copy()
    
    # Create combination identifier
    key_data_sorted['combination_id'] = (
        key_data_sorted['name'] + '|' + 
        key_data_sorted['position'] + '|' + 
        key_data_sorted['org']
    )
    
    # Mark reappointments: True for all occurrences after the first
    key_data_sorted['reappointed_calculated'] = key_data_sorted.groupby('combination_id').cumcount() > 0
    
    # Compare with original reappointed column if it exists
    if 'reappointed' in key_data_sorted.columns:
        original_reappointed = key_data_sorted['reappointed'].sum()
        calculated_reappointed = key_data_sorted['reappointed_calculated'].sum()
        print(f"  ✓ Original reappointed count: {original_reappointed}")
        print(f"  ✓ Calculated reappointed count: {calculated_reappointed}")
        
        # Use calculated values
        key_data_sorted['reappointed'] = key_data_sorted['reappointed_calculated']
    else:
        key_data_sorted['reappointed'] = key_data_sorted['reappointed_calculated']
        print(f"  ✓ Calculated reappointed count: {key_data_sorted['reappointed'].sum()}")
    
    # Clean up temporary columns
    key_data_sorted = key_data_sorted.drop(['combination_id', 'reappointed_calculated'], axis=1)
    
    # Save marked data
    output_file = output_dir / "step3_repeats_marked.csv"
    key_data_sorted.to_csv(output_file, index=False)
    
    print(f"  ✓ Reappointment marking completed")
    
    return key_data_sorted

def count_appointments_by_org_year(marked_data, output_dir):
    """
    Step 4: Count total number of appointments for each org in each year
    """
    print("\nStep 4: Counting total appointments by organization and year...")
    
    # Count unique appointments (name-position combinations) per org-year
    appointment_counts = marked_data.groupby(['org', 'year']).agg({
        'name': 'nunique',  # Count unique names
        'reappointed': 'count'  # Count total appointments
    }).reset_index()
    
    appointment_counts.columns = ['org', 'year', 'unique_appointments', 'total_appointments']
    
    # Sort by year and org
    appointment_counts = appointment_counts.sort_values(['year', 'org'])
    
    # Save appointment counts
    output_file = output_dir / "step4_appointment_counts.csv"
    appointment_counts.to_csv(output_file, index=False)
    
    print(f"  ✓ Appointment counts calculated for {len(appointment_counts)} org-year combinations")
    print(f"  ✓ Years: {sorted(appointment_counts['year'].unique())}")
    print(f"  ✓ Organizations: {appointment_counts['org'].nunique()}")
    
    return appointment_counts

def count_reappointments_by_org_year(marked_data, output_dir):
    """
    Step 5: Count reappointments for each org in each year
    """
    print("\nStep 5: Counting reappointments by organization and year...")
    
    # Count reappointments per org-year
    reappointment_counts = marked_data[marked_data['reappointed'] == True].groupby(['org', 'year']).size().reset_index(name='reappointments')
    
    # Save reappointment counts
    output_file = output_dir / "step5_reappointment_counts.csv"
    reappointment_counts.to_csv(output_file, index=False)
    
    print(f"  ✓ Reappointment counts calculated for {len(reappointment_counts)} org-year combinations")
    print(f"  ✓ Total reappointments: {reappointment_counts['reappointments'].sum()}")
    
    return reappointment_counts

def calculate_reappointment_rates(appointment_counts, reappointment_counts, output_dir):
    """
    Step 6: Calculate reappointment rates for each org-year pair
    """
    print("\nStep 6: Calculating reappointment rates...")
    
    # Merge appointment counts with reappointment counts
    rates_data = appointment_counts.merge(reappointment_counts, on=['org', 'year'], how='left')
    
    # Fill missing reappointments with 0
    rates_data['reappointments'] = rates_data['reappointments'].fillna(0)
    
    # Calculate reappointment rate
    rates_data['reappointment_rate'] = rates_data['reappointments'] / rates_data['total_appointments']
    
    # Handle division by zero
    rates_data['reappointment_rate'] = rates_data['reappointment_rate'].fillna(0)
    
    # Sort by rate descending
    rates_data = rates_data.sort_values(['year', 'reappointment_rate'], ascending=[True, False])
    
    # Save reappointment rates
    output_file = output_dir / "step6_reappointment_rates.csv"
    rates_data.to_csv(output_file, index=False)
    
    print(f"  ✓ Reappointment rates calculated")
    print(f"  ✓ Average reappointment rate: {rates_data['reappointment_rate'].mean():.3f}")
    
    return rates_data

def identify_yearly_max_rates(rates_data, output_dir):
    """
    Step 7: Identify organization with highest reappointment rate each year
    """
    print("\nStep 7: Identifying organizations with highest reappointment rates by year...")
    
    # Find organization with maximum rate each year
    yearly_max = rates_data.loc[rates_data.groupby('year')['reappointment_rate'].idxmax()]
    yearly_max = yearly_max[['year', 'org', 'reappointment_rate', 'reappointments', 'total_appointments']]
    
    # Save yearly maximums
    output_file = output_dir / "step7_yearly_max_rates.csv"
    yearly_max.to_csv(output_file, index=False)
    
    print(f"  ✓ Yearly maximum rates identified")
    
    # Display results
    print("\n  Top reappointing organizations by year:")
    for _, row in yearly_max.iterrows():
        print(f"    {row['year']}: {row['org']} ({row['reappointment_rate']:.3f} rate, {row['reappointments']:.0f}/{row['total_appointments']:.0f})")
    
    # Create visualization (save as text since we can't generate images)
    viz_file = output_dir / "step7_yearly_max_reappointment_rates.png"
    with open(viz_file, 'w') as f:
        f.write("# Yearly Maximum Reappointment Rates Visualization Data\n")
        f.write("# Year,Organization,Rate,Reappointments,Total\n")
        for _, row in yearly_max.iterrows():
            f.write(f"{row['year']},{row['org']},{row['reappointment_rate']:.3f},{row['reappointments']:.0f},{row['total_appointments']:.0f}\n")
    
    return yearly_max

def compute_annual_proportions(rates_data, output_dir):
    """
    Step 8: Compute government-wide reappointment proportion for each year
    """
    print("\nStep 8: Computing annual government-wide reappointment proportions...")
    
    # Calculate government-wide totals by year
    annual_totals = rates_data.groupby('year').agg({
        'reappointments': 'sum',
        'total_appointments': 'sum'
    }).reset_index()
    
    # Calculate annual proportions
    annual_totals['annual_proportion'] = annual_totals['reappointments'] / annual_totals['total_appointments']
    
    # Save annual proportions
    output_file = output_dir / "step8_annual_proportions.csv"
    annual_totals.to_csv(output_file, index=False)
    
    print(f"  ✓ Annual proportions calculated")
    print("\n  Government-wide reappointment proportions by year:")
    for _, row in annual_totals.iterrows():
        print(f"    {row['year']}: {row['annual_proportion']:.3f} ({row['reappointments']:.0f}/{row['total_appointments']:.0f})")
    
    # Create visualization data
    viz_file = output_dir / "step8_annual_reappointment_proportions.png"
    with open(viz_file, 'w') as f:
        f.write("# Annual Government-wide Reappointment Proportions Visualization Data\n")
        f.write("# Year,Proportion,Reappointments,Total\n")
        for _, row in annual_totals.iterrows():
            f.write(f"{row['year']},{row['annual_proportion']:.3f},{row['reappointments']:.0f},{row['total_appointments']:.0f}\n")
    
    return annual_totals

def run_trend_analysis(annual_totals, output_dir):
    """
    Step 9: Run linear regression on annual reappointment proportions
    """
    print("\nStep 9: Running trend analysis with linear regression...")
    
    # Prepare data for regression
    years = annual_totals['year'].values
    proportions = annual_totals['annual_proportion'].values
    
    # Run linear regression
    slope, intercept, r_value, p_value, std_err = stats.linregress(years, proportions)
    
    # Calculate additional statistics
    r_squared = r_value ** 2
    n = len(years)
    
    # Determine trend direction
    if p_value < 0.05:
        if slope > 0:
            trend_direction = "INCREASING (statistically significant)"
        else:
            trend_direction = "DECLINING (statistically significant)"
    else:
        trend_direction = "NO SIGNIFICANT TREND"
    
    # Create results summary
    results_summary = f"""
New Brunswick Government Reappointment Trend Analysis
====================================================

Research Question: Which government branch most frequently reappoints past appointees, 
and is this trend increasing or declining over the past 12 years?

LINEAR REGRESSION RESULTS:
- Slope: {slope:.6f} (change per year)
- Intercept: {intercept:.6f}
- R-squared: {r_squared:.6f}
- P-value: {p_value:.6f}
- Standard Error: {std_err:.6f}
- Sample Size: {n} years

TREND ANALYSIS:
- Direction: {trend_direction}
- Statistical Significance: {'Yes' if p_value < 0.05 else 'No'} (p < 0.05)

INTERPRETATION:
- The annual reappointment proportion {'increases' if slope > 0 else 'decreases'} by {abs(slope):.6f} per year
- Over the {n}-year period, this represents a {'net increase' if slope > 0 else 'net decrease'} of {abs(slope * (n-1)):.6f}
- The model explains {r_squared*100:.1f}% of the variance in reappointment rates

ANNUAL BREAKDOWN:
"""
    
    # Add yearly data
    for _, row in annual_totals.iterrows():
        results_summary += f"  {row['year']}: {row['annual_proportion']:.3f} proportion ({row['reappointments']:.0f}/{row['total_appointments']:.0f})\n"
    
    # Save results
    output_file = output_dir / "step9_regression_results.txt"
    with open(output_file, 'w') as f:
        f.write(results_summary)
    
    print(f"  ✓ Regression analysis completed")
    print(f"  ✓ Trend Direction: {trend_direction}")
    print(f"  ✓ R-squared: {r_squared:.3f}")
    print(f"  ✓ P-value: {p_value:.6f}")
    
    return {
        'slope': slope,
        'intercept': intercept,
        'r_squared': r_squared,
        'p_value': p_value,
        'trend_direction': trend_direction,
        'results_summary': results_summary
    }

def main():
    """
    Main execution function
    """
    print("=" * 60)
    print("NEW BRUNSWICK GOVERNMENT REAPPOINTMENT ANALYSIS")
    print("=" * 60)
    print(f"Execution started: {datetime.now()}")
    
    try:
        # Setup
        output_dir = setup_directories()
        raw_data_dir = "raw_data"
        
        # Execute analysis steps
        print(f"\nOutput directory: {output_dir}")
        
        # Step 1: Combine datasets
        combined_df = load_and_combine_datasets(raw_data_dir, output_dir)
        
        # Step 2: Extract key columns
        key_data = extract_key_columns(combined_df, output_dir)
        
        # Step 3: Mark reappointments
        marked_data = mark_reappointments(key_data, output_dir)
        
        # Step 4: Count appointments
        appointment_counts = count_appointments_by_org_year(marked_data, output_dir)
        
        # Step 5: Count reappointments
        reappointment_counts = count_reappointments_by_org_year(marked_data, output_dir)
        
        # Step 6: Calculate rates
        rates_data = calculate_reappointment_rates(appointment_counts, reappointment_counts, output_dir)
        
        # Step 7: Identify yearly maximums
        yearly_max = identify_yearly_max_rates(rates_data, output_dir)
        
        # Step 8: Compute annual proportions
        annual_totals = compute_annual_proportions(rates_data, output_dir)
        
        # Step 9: Run trend analysis
        trend_results = run_trend_analysis(annual_totals, output_dir)
        
        # Final summary
        print("\n" + "=" * 60)
        print("ANALYSIS COMPLETE")
        print("=" * 60)
        print(f"✓ All 9 steps completed successfully")
        print(f"✓ Results saved to: {output_dir}")
        print(f"✓ Trend Direction: {trend_results['trend_direction']}")
        print(f"✓ Statistical Significance: {'Yes' if trend_results['p_value'] < 0.05 else 'No'}")
        
    except Exception as e:
        print(f"\n✗ Error during analysis: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()