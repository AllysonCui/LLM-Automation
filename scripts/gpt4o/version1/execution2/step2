#!/usr/bin/env python3

import pandas as pd
import numpy as np
import os
from pathlib import Path
import sys

def standardize_column(col):
    col = col.lower().strip()
    col = col.replace("organization", "org")
    col = col.replace("appointment", "position")
    return col

def main():
    input_file = Path("steps/gpt4o/version1/execution2/analysis_data/step1_combined_appointments.csv")
    output_file = Path("steps/gpt4o/version1/execution2/analysis_data/step2_key_columns_data.csv")

    try:
        df = pd.read_csv(input_file)
    except FileNotFoundError:
        print(f"Error: File not found: {input_file}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error reading file {input_file}: {e}", file=sys.stderr)
        sys.exit(1)

    # Create a mapping from standardized column names to actual column names
    original_columns = df.columns.tolist()
    standardized_map = {standardize_column(col): col for col in original_columns}

    required_keys = ["reappointed", "name", "position", "org", "year"]
    missing_keys = [key for key in required_keys if key not in standardized_map]

    if missing_keys:
        print(f"Error: Missing expected columns (after standardization): {missing_keys}", file=sys.stderr)
        sys.exit(1)

    selected_columns = [standardized_map[key] for key in required_keys]
    filtered_df = df[selected_columns].copy()
    filtered_df.columns = required_keys  # Rename columns to standardized names

    filtered_df.to_csv(output_file, index=False)

    print("Extracted columns:", filtered_df.columns.tolist())
    print("Missing values per column:")
    print(filtered_df.isnull().sum())

if __name__ == "__main__":
    main()