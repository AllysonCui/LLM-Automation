#!/usr/bin/env python3

import pandas as pd
import os
from pathlib import Path

# Define the path to the raw data and output directory
raw_data_dir = Path("raw_data")
output_dir = Path("scripts/gpt4o/version1/execution5/analysis_data")

# Create output directory if it doesn't exist
output_dir.mkdir(parents=True, exist_ok=True)

# Define a list to hold the individual DataFrames
dfs = []

# Loop through years 2013 to 2024 and load each file
for year in range(2013, 2025):
    file_path = raw_data_dir / f"appointments_{year}.csv"
    
    try:
        # Load the CSV file into a DataFrame
        df = pd.read_csv(file_path)
        
        # Add a 'year' column to the DataFrame
        df['year'] = year
        
        # Append to the list of DataFrames
        dfs.append(df)
        
    except FileNotFoundError:
        print(f"Error: File {file_path} not found. Skipping this file.")
    except pd.errors.EmptyDataError:
        print(f"Error: File {file_path} is empty. Skipping this file.")
    except Exception as e:
        print(f"Error processing file {file_path}: {e}")

# Combine all DataFrames into a single DataFrame
if dfs:
    combined_df = pd.concat(dfs, ignore_index=True)

    # Save the combined dataset
    combined_file_path = output_dir / "step1_combined_appointments.csv"
    combined_df.to_csv(combined_file_path, index=False)

    # Print the shape and basic info about the combined dataset
    print("Combined dataset shape:", combined_df.shape)
    print("Combined dataset info:")
    combined_df.info()
else:
    print("No data was loaded, skipping the combination process.")
