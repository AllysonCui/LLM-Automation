#!/usr/bin/env python3
"""
step to extract key columns from combined appointments dataset.

Steps:
1. Load 'combined_appointments.csv' from steps/gpt4o/version1/analysis_data
2. Identify and extract columns: 'reappointed', 'name', 'position', 'org' (with flexibility in names)
3. Add 'year' column
4. Save the result as 'step2_key_columns_data.csv'
5. Print column info and missing value summary

Author: GPT-4o
Date: 2025-06-11
"""

import pandas as pd
from pathlib import Path
import sys

# Define potential variants of the target columns
COLUMN_MAP = {
    "reappointed": ["reappointed", "re_appointed", "re-appointment"],
    "name": ["name", "appointee", "full_name"],
    "position": ["position", "appointment", "role"],
    "org": ["org", "organization", "agency"],
    "year": ["year"]
}

def resolve_column(df, target):
    """Return the first matching column from the list of possible variants."""
    for variant in COLUMN_MAP[target]:
        if variant in df.columns:
            return variant
    return None

def main():
    input_path = Path("steps/gpt4o/version1/analysis_data/step1_combined_appointments.csv")
    output_path = Path("steps/gpt4o/version1/analysis_data/step2_key_columns_data.csv")

    try:
        df = pd.read_csv(input_path)
    except FileNotFoundError:
        print(f"✗ File not found: {input_path}")
        sys.exit(1)
    except Exception as e:
        print(f"✗ Error loading file: {e}")
        sys.exit(1)

    # Resolve actual column names from variants
    resolved_cols = {}
    for key in ["reappointed", "name", "position", "org", "year"]:
        col = resolve_column(df, key)
        if col:
            resolved_cols[key] = col
        else:
            print(f"✗ Could not find a matching column for '{key}'.")
            sys.exit(1)

    # Extract selected columns and rename to standard keys
    df_filtered = df[[resolved_cols[key] for key in resolved_cols]].copy()
    df_filtered.columns = list(resolved_cols.keys())

    # Save filtered dataset
    df_filtered.to_csv(output_path, index=False)
    print(f"✓ Saved filtered dataset to {output_path}")

    # Print info and missing value summary
    print(f"\n→ Extracted columns: {list(df_filtered.columns)}")
    print(f"→ Dataset shape: {df_filtered.shape}")

    missing = df_filtered.isnull().sum()
    if missing.sum() > 0:
        print("\n→ Missing values:")
        for col, count in missing.items():
            if count > 0:
                pct = (count / len(df_filtered)) * 100
                print(f"  {col}: {count:,} ({pct:.1f}%)")
    else:
        print("\n→ No missing values detected.")

if __name__ == "__main__":
    main()
