import pandas as pd
from pathlib import Path
import os

# Directories
RAW_DATA_DIR = Path("raw_data")
OUTPUT_DIR = Path("scripts/gpt4o/version2/execution5/analysis_data")
OUTPUT_FILE = OUTPUT_DIR / "step1_combined_appointments.csv"

# Ensure output directory exists
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Initialize list to collect dataframes
dataframes = []
missing_files = []

# Load each file and append to list
for year in range(2013, 2025):
    file_path = RAW_DATA_DIR / f"appointments_{year}.csv"
    if file_path.exists():
        try:
            df = pd.read_csv(file_path)
            df['source_year'] = year  # Tag data with year for traceability
            dataframes.append(df)
            print(f"Loaded {file_path.name} with {len(df)} records.")
        except Exception as e:
            print(f"Error reading {file_path.name}: {e}")
    else:
        print(f"File not found: {file_path.name}")
        missing_files.append(file_path.name)

# Combine all loaded dataframes
if dataframes:
    combined_df = pd.concat(dataframes, ignore_index=True)
    combined_df.to_csv(OUTPUT_FILE, index=False)
    print(f"\nSuccessfully combined {len(dataframes)} files into {OUTPUT_FILE.name}")
    print(f"Total records: {len(combined_df)}")
else:
    print("\nNo dataframes were loaded. Check missing files and errors.")

# Report missing files if any
if missing_files:
    print("\nMissing files:")
    for fname in missing_files:
        print(f"- {fname}")
