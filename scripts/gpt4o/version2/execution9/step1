import pandas as pd
from pathlib import Path

# Define input and output paths
raw_data_dir = Path("raw_data")
output_dir = Path("scripts/gpt4o/version2/execution9/analysis_data")
output_file = output_dir / "step1_combined_appointments.csv"

# Ensure output directory exists
output_dir.mkdir(parents=True, exist_ok=True)

# Initialize empty list to store dataframes
all_dfs = []

print("Step 1: Combining datasets from 2013 to 2024...")

# Loop through each year, read the corresponding CSV, and append to list
for year in range(2013, 2025):
    file_path = raw_data_dir / f"appointments_{year}.csv"
    try:
        df = pd.read_csv(file_path)
        df["source_year"] = year  # Add a column to track the year of source
        all_dfs.append(df)
        print(f"  Loaded {file_path.name} with {len(df)} records.")
    except FileNotFoundError:
        print(f"  WARNING: File not found: {file_path}")
    except pd.errors.EmptyDataError:
        print(f"  WARNING: File is empty: {file_path}")
    except Exception as e:
        print(f"  ERROR reading {file_path.name}: {e}")

# Concatenate all dataframes
if all_dfs:
    combined_df = pd.concat(all_dfs, ignore_index=True)
    print(f"\nTotal combined records: {len(combined_df)}")

    # Save to CSV
    combined_df.to_csv(output_file, index=False)
    print(f"Combined dataset saved to: {output_file}")
else:
    print("No dataframes were loaded. Exiting.")