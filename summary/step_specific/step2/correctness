import os
import pandas as pd

# Columns to compare
key_columns = ["reappointed", "name", "position", "org", "year"]

# Normalize string values for case-insensitive comparison
def normalize_cell(value):
    if pd.isna(value):
        return "nan"
    if isinstance(value, str):
        normalized = value.strip().lower()
        if normalized == "nan" or normalized == "unknown":
            return "nan"
        return normalized
    return str(value).lower()

# Sort order priority
sort_priority = ["name", "position", "org", "reappointed", "year"]

def create_sort_key(df):
    normalized_df = df[sort_priority].applymap(normalize_cell)
    return normalized_df.apply(lambda row: tuple(row), axis=1)

def safe_rename_columns(df):
    rename_dict = {}
    if "organization" in df.columns:
        rename_dict["organization"] = "org"
    if "source_year" in df.columns:
        rename_dict["source_year"] = "year"
    if "data_year" in df.columns:
        rename_dict["data_year"] = "year"
    return df.rename(columns=rename_dict)

# Load correct answer
correct_path = "summary/step_specific/step2/correct_answer/answer1.csv"
try:
    correct_df = pd.read_csv(correct_path)
    correct_df = safe_rename_columns(correct_df)
    correct_df = correct_df[key_columns].copy()
except Exception as e:
    print(f"Failed to read correct answer file: {e}")
    exit(1)

# Normalize and sort correct answer
sort_key = create_sort_key(correct_df)
correct_df = correct_df.iloc[sort_key.argsort()].reset_index(drop=True)
normalized_correct_df = correct_df[key_columns].applymap(normalize_cell)

# Prepare expected executions
expected_branches = [
    ("gpt4o", "version1"),
    ("gpt4o", "version2"),
    ("gpt4o", "version3"),
    ("claudeopus4", "version1"),
    ("claudeopus4", "version2"),
    ("claudeopus4", "version3"),
    ("claudesonnet4", "version1"),
    ("claudesonnet4", "version2"),
    ("claudesonnet4", "version3")
]

expected_executions = {
    f"scripts/{model}/{version}/execution{n}"
    for model, version in expected_branches
    for n in range(1, 11)
}

found_executions = set()
skip_executions = []

root_dir = "scripts"

for model in os.listdir(root_dir):
    model_path = os.path.join(root_dir, model)
    if not os.path.isdir(model_path):
        continue

    for version in os.listdir(model_path):
        version_path = os.path.join(model_path, version)
        if not os.path.isdir(version_path):
            continue

        for folder in os.listdir(version_path):
            if not folder.startswith("execution"):
                continue

            execution_dir = f"{model}/{version}/{folder}"
            found_executions.add(f"scripts/{execution_dir}")
            step2_file = os.path.join(version_path, folder, "analysis_data", "step2_key_columns_data.csv")

            if not os.path.exists(step2_file):
                continue

            try:
                df = pd.read_csv(step2_file)
                df = safe_rename_columns(df)

                if not all(col in df.columns for col in key_columns):
                    print(f"{step2_file}: Missing columns")
                    continue

                df = df[key_columns].copy()
                sort_key = create_sort_key(df)
                df = df.iloc[sort_key.argsort()].reset_index(drop=True)
                normalized_df = df[key_columns].applymap(normalize_cell)

                if len(df) != len(correct_df):
                    print(f"{step2_file}: Row count mismatch ({len(df)} vs {len(correct_df)})")
                    skip_executions.append(execution_dir)
                    continue

                mismatches = (normalized_df != normalized_correct_df)
                if mismatches.any().any():
                    print(f"{step2_file}: Value mismatch found")
                    skip_executions.append(execution_dir)

                    mismatch_count = 0
                    for idx in mismatches.index:
                        for col in key_columns:
                            if mismatches.at[idx, col]:
                                print(f"  Row {idx}, Column '{col}': found = '{df.at[idx, col]}', expected = '{correct_df.at[idx, col]}'")
                                mismatch_count += 1
                                if mismatch_count >= 5:
                                    break
                        if mismatch_count >= 5:
                            break

            except Exception as e:
                print(f"{step2_file}: Failed to read/compare ({e})")

# Report missing executions
missing = expected_executions - found_executions
if missing:
    print(f"\nMissing {len(missing)} executions:")
    for m in sorted(missing):
        print(f"  {m}/analysis_data/step2_key_columns_data.csv")
else:
    print(f"\nâœ“ All {len(expected_executions)} expected executions were found")

# Save to CSV (only execution paths, no /scripts/ prefix or file suffix)
output_dir = "summary/step_specific/step3"
os.makedirs(output_dir, exist_ok=True)
skip_path = os.path.join(output_dir, "executions_to_skip.csv")

pd.DataFrame({"execution": skip_executions}).to_csv(skip_path, index=False)
print(f"\nðŸš« Saved {len(skip_executions)} problematic executions to: {skip_path}")
